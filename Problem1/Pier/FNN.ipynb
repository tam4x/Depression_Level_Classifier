{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "# Now you can import your module\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from NN import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Training, Validation and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "ID_1          80\n",
      "ID_2          80\n",
      "group_id      80\n",
      "SEX           80\n",
      "AGE           80\n",
      "              ..\n",
      "FEATURE_51    80\n",
      "FEATURE_52    80\n",
      "FEATURE_53    80\n",
      "FEATURE_54    80\n",
      "FEATURE_55    80\n",
      "Length: 65, dtype: int64\n",
      "1.0\n",
      "ID_1          80\n",
      "ID_2          80\n",
      "group_id      80\n",
      "SEX           80\n",
      "AGE           80\n",
      "              ..\n",
      "FEATURE_51    80\n",
      "FEATURE_52    80\n",
      "FEATURE_53    80\n",
      "FEATURE_54    80\n",
      "FEATURE_55    80\n",
      "Length: 65, dtype: int64\n",
      "2.0\n",
      "ID_1          80\n",
      "ID_2          80\n",
      "group_id      80\n",
      "SEX           80\n",
      "AGE           80\n",
      "              ..\n",
      "FEATURE_51    80\n",
      "FEATURE_52    80\n",
      "FEATURE_53    80\n",
      "FEATURE_54    80\n",
      "FEATURE_55    80\n",
      "Length: 65, dtype: int64\n",
      "3.0\n",
      "ID_1          80\n",
      "ID_2          80\n",
      "group_id      80\n",
      "SEX           80\n",
      "AGE           80\n",
      "              ..\n",
      "FEATURE_51    80\n",
      "FEATURE_52    80\n",
      "FEATURE_53    80\n",
      "FEATURE_54    80\n",
      "FEATURE_55    80\n",
      "Length: 65, dtype: int64\n",
      "6.0\n",
      "ID_1          80\n",
      "ID_2          80\n",
      "group_id      80\n",
      "SEX           80\n",
      "AGE           80\n",
      "              ..\n",
      "FEATURE_51    80\n",
      "FEATURE_52    80\n",
      "FEATURE_53    80\n",
      "FEATURE_54    80\n",
      "FEATURE_55    80\n",
      "Length: 65, dtype: int64\n",
      "7.0\n",
      "ID_1          80\n",
      "ID_2          80\n",
      "group_id      80\n",
      "SEX           80\n",
      "AGE           80\n",
      "              ..\n",
      "FEATURE_51    80\n",
      "FEATURE_52    80\n",
      "FEATURE_53    80\n",
      "FEATURE_54    80\n",
      "FEATURE_55    80\n",
      "Length: 65, dtype: int64\n",
      "8.0\n",
      "ID_1          80\n",
      "ID_2          80\n",
      "group_id      80\n",
      "SEX           80\n",
      "AGE           80\n",
      "              ..\n",
      "FEATURE_51    80\n",
      "FEATURE_52    80\n",
      "FEATURE_53    80\n",
      "FEATURE_54    80\n",
      "FEATURE_55    80\n",
      "Length: 65, dtype: int64\n",
      "9.0\n",
      "ID_1          80\n",
      "ID_2          80\n",
      "group_id      80\n",
      "SEX           80\n",
      "AGE           80\n",
      "              ..\n",
      "FEATURE_51    80\n",
      "FEATURE_52    80\n",
      "FEATURE_53    80\n",
      "FEATURE_54    80\n",
      "FEATURE_55    80\n",
      "Length: 65, dtype: int64\n",
      "---Number of Non-Depression and Depression---\n",
      "240 400\n",
      "torch.Size([460, 56]) torch.Size([460]) torch.Size([116, 56]) torch.Size([116]) torch.Size([64, 56]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/Threshold_3_Operator_-_Depressionfeature_BP_PHQ_9_PercentofDataset_100.csv')\n",
    "print_information(df)\n",
    "# 0.9 train, 0.1 test\n",
    "train_df, test_df = train_test_split(df, test_size=0.1, random_state=42)\n",
    "# 0.8 train, 0.2 validation\n",
    "train_df, validation_df = train_test_split(train_df, train_size=0.8, random_state=42)\n",
    "\n",
    "train_features, train_targets = df_to_tensor(train_df,features_column='FEATURES', target_col='Depression')\n",
    "validation_features, validation_targets = df_to_tensor(validation_df, features_column='FEATURES', target_col='Depression')\n",
    "test_features, test_targets = df_to_tensor(test_df, features_column='FEATURES', target_col='Depression')\n",
    "\n",
    "print(train_features.shape, train_targets.shape, validation_features.shape, validation_targets.shape, test_features.shape, test_targets.shape)\n",
    "#print(train_features.shape, train_targets.shape, test_features.shape, test_targets.shape)\n",
    "\n",
    "train_dataset = CustomDataset(train_features, train_targets)\n",
    "validation_dataset = CustomDataset(validation_features, validation_targets)\n",
    "test_dataset = CustomDataset(test_features, test_targets)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=2, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get the best Model with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creating a configuration with 56 Features as input that where extracted from the wavelet analysis\n",
    "- 128 Neurons as the hidden layer\n",
    "- Number of epochs is 60\n",
    "- the Loss Function is BCE because we have a binary classification problem (Binary Cross Entropy)\n",
    "- There are 3 model types\n",
    "    - Model_0 with 1 Hidden Layer so meaning 56 -> 128 -> 1 neuron (Activation Function ReLU)\n",
    "    - Model_1 has 3 Hidden Layer 56 -> 128 -> 64 -> 32 -> 1 neuron (Activation Function ReLU)\n",
    "    - Model_2 has the same architecure as Model_1 only with a Activation Function called tanh that has the same property as the sigmoid activation function\n",
    "- For the Hyperparameter Tuning I select the parameters\n",
    "    - learning_rate\n",
    "    - momentum\n",
    "    - optimizer (Adam and SGD)\n",
    "    - model type\n",
    "- After the hyperparameter tuning is done the best performing model is used and trained on again with a bigger number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6277, Accuracy: 62.50%\n",
      "Model: 1 is being trained with optimizer: Adam and learning rate: 0.001 and Model_0\n",
      "Loss: 0.6749, Accuracy: 67.19%\n",
      "Model: 2 is being trained with optimizer: Adam and learning rate: 0.003 and Model_0\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6445, Accuracy: 65.62%\n",
      "Model: 3 is being trained with optimizer: Adam and learning rate: 0.006 and Model_0\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.8689, Accuracy: 56.25%\n",
      "Model: 4 is being trained with optimizer: Adam and learning rate: 0.01 and Model_0\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6018, Accuracy: 64.06%\n",
      "Model: 5 is being trained with optimizer: SGD and learning rate: 0.001 and Model_0\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.5647, Accuracy: 60.94%\n",
      "Model: 6 is being trained with optimizer: SGD and learning rate: 0.003 and Model_0\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.5442, Accuracy: 60.94%\n",
      "Model: 7 is being trained with optimizer: SGD and learning rate: 0.006 and Model_0\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.5814, Accuracy: 65.62%\n",
      "Model: 8 is being trained with optimizer: SGD and learning rate: 0.01 and Model_0\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6427, Accuracy: 54.69%\n",
      "Model: 9 is being trained with optimizer: SGD and learning rate: 0.001 and Model_0\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6065, Accuracy: 64.06%\n",
      "Model: 10 is being trained with optimizer: SGD and learning rate: 0.003 and Model_0\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6527, Accuracy: 60.94%\n",
      "Model: 11 is being trained with optimizer: SGD and learning rate: 0.006 and Model_0\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.7043, Accuracy: 56.25%\n",
      "Model: 12 is being trained with optimizer: SGD and learning rate: 0.01 and Model_0\n",
      "Loss: 0.5765, Accuracy: 60.94%\n",
      "Model: 13 is being trained with optimizer: SGD and learning rate: 0.001 and Model_0\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6872, Accuracy: 56.25%\n",
      "Model: 14 is being trained with optimizer: SGD and learning rate: 0.003 and Model_0\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6856, Accuracy: 56.25%\n",
      "Model: 15 is being trained with optimizer: SGD and learning rate: 0.006 and Model_0\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.7057, Accuracy: 56.25%\n",
      "Model: 16 is being trained with optimizer: SGD and learning rate: 0.01 and Model_0\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.5741, Accuracy: 57.81%\n",
      "Model: 17 is being trained with optimizer: Adam and learning rate: 0.001 and Model_1\n",
      "Loss: 0.5874, Accuracy: 67.19%\n",
      "Model: 18 is being trained with optimizer: Adam and learning rate: 0.003 and Model_1\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6014, Accuracy: 67.19%\n",
      "Model: 19 is being trained with optimizer: Adam and learning rate: 0.006 and Model_1\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6931, Accuracy: 56.25%\n",
      "Model: 20 is being trained with optimizer: Adam and learning rate: 0.01 and Model_1\n",
      "Loss: 0.5692, Accuracy: 62.50%\n",
      "Model: 21 is being trained with optimizer: SGD and learning rate: 0.001 and Model_1\n",
      "Loss: 0.5332, Accuracy: 70.31%\n",
      "Model: 22 is being trained with optimizer: SGD and learning rate: 0.003 and Model_1\n",
      "Loss: 0.5937, Accuracy: 65.62%\n",
      "Model: 23 is being trained with optimizer: SGD and learning rate: 0.006 and Model_1\n",
      "Loss: 0.6011, Accuracy: 64.06%\n",
      "Model: 24 is being trained with optimizer: SGD and learning rate: 0.01 and Model_1\n",
      "Loss: 0.6252, Accuracy: 60.94%\n",
      "Model: 25 is being trained with optimizer: SGD and learning rate: 0.001 and Model_1\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.5787, Accuracy: 56.25%\n",
      "Model: 26 is being trained with optimizer: SGD and learning rate: 0.003 and Model_1\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.5255, Accuracy: 70.31%\n",
      "Model: 27 is being trained with optimizer: SGD and learning rate: 0.006 and Model_1\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6871, Accuracy: 56.25%\n",
      "Model: 28 is being trained with optimizer: SGD and learning rate: 0.01 and Model_1\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.5681, Accuracy: 67.19%\n",
      "Model: 29 is being trained with optimizer: SGD and learning rate: 0.001 and Model_1\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6923, Accuracy: 56.25%\n",
      "Model: 30 is being trained with optimizer: SGD and learning rate: 0.003 and Model_1\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.7169, Accuracy: 56.25%\n",
      "Model: 31 is being trained with optimizer: SGD and learning rate: 0.006 and Model_1\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6906, Accuracy: 56.25%\n",
      "Model: 32 is being trained with optimizer: SGD and learning rate: 0.01 and Model_1\n",
      "Loss: 0.6870, Accuracy: 62.50%\n",
      "Model: 33 is being trained with optimizer: Adam and learning rate: 0.001 and Model_2\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.7456, Accuracy: 56.25%\n",
      "Model: 34 is being trained with optimizer: Adam and learning rate: 0.003 and Model_2\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6912, Accuracy: 56.25%\n",
      "Model: 35 is being trained with optimizer: Adam and learning rate: 0.006 and Model_2\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6930, Accuracy: 56.25%\n",
      "Model: 36 is being trained with optimizer: Adam and learning rate: 0.01 and Model_2\n",
      "Loss: 0.6153, Accuracy: 67.19%\n",
      "Model: 37 is being trained with optimizer: SGD and learning rate: 0.001 and Model_2\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6525, Accuracy: 59.38%\n",
      "Model: 38 is being trained with optimizer: SGD and learning rate: 0.003 and Model_2\n",
      "Loss: 0.5459, Accuracy: 64.06%\n",
      "Model: 39 is being trained with optimizer: SGD and learning rate: 0.006 and Model_2\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.7311, Accuracy: 57.81%\n",
      "Model: 40 is being trained with optimizer: SGD and learning rate: 0.01 and Model_2\n",
      "Loss: 0.5488, Accuracy: 59.38%\n",
      "Model: 41 is being trained with optimizer: SGD and learning rate: 0.001 and Model_2\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.7069, Accuracy: 59.38%\n",
      "Model: 42 is being trained with optimizer: SGD and learning rate: 0.003 and Model_2\n",
      "Loss: 0.6398, Accuracy: 68.75%\n",
      "Model: 43 is being trained with optimizer: SGD and learning rate: 0.006 and Model_2\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 1.0396, Accuracy: 56.25%\n",
      "Model: 44 is being trained with optimizer: SGD and learning rate: 0.01 and Model_2\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6440, Accuracy: 67.19%\n",
      "Model: 45 is being trained with optimizer: SGD and learning rate: 0.001 and Model_2\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6888, Accuracy: 56.25%\n",
      "Model: 46 is being trained with optimizer: SGD and learning rate: 0.003 and Model_2\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6915, Accuracy: 56.25%\n",
      "Model: 47 is being trained with optimizer: SGD and learning rate: 0.006 and Model_2\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 43.7500, Accuracy: 56.25%\n",
      "Model: 48 is being trained with optimizer: SGD and learning rate: 0.01 and Model_2\n",
      "{('Model_0', 'Adam', 0.001): {'validation_loss': 0.627694875234738, 'accuracy': 62.5}, ('Model_0', 'Adam', 0.003): {'validation_loss': 0.6748736678273417, 'accuracy': 67.1875}, ('Model_0', 'Adam', 0.006): {'validation_loss': 0.6444999948143959, 'accuracy': 65.625}, ('Model_0', 'Adam', 0.01): {'validation_loss': 0.8688740816141944, 'accuracy': 56.25}, ('Model_0', 'SGD', 0.001, 0.9): {'validation_loss': 0.6017792639322579, 'accuracy': 64.0625}, ('Model_0', 'SGD', 0.003, 0.9): {'validation_loss': 0.5646609325776808, 'accuracy': 60.9375}, ('Model_0', 'SGD', 0.006, 0.9): {'validation_loss': 0.5442246696911752, 'accuracy': 60.9375}, ('Model_0', 'SGD', 0.01, 0.9): {'validation_loss': 0.5814009294845164, 'accuracy': 65.625}, ('Model_0', 'SGD', 0.001, 0.95): {'validation_loss': 0.6426819090847857, 'accuracy': 54.6875}, ('Model_0', 'SGD', 0.003, 0.95): {'validation_loss': 0.6065371471922845, 'accuracy': 64.0625}, ('Model_0', 'SGD', 0.006, 0.95): {'validation_loss': 0.6526523400098085, 'accuracy': 60.9375}, ('Model_0', 'SGD', 0.01, 0.95): {'validation_loss': 0.7043408574536443, 'accuracy': 56.25}, ('Model_0', 'SGD', 0.001, 0.99): {'validation_loss': 0.5765258271130733, 'accuracy': 60.9375}, ('Model_0', 'SGD', 0.003, 0.99): {'validation_loss': 0.6871925815939903, 'accuracy': 56.25}, ('Model_0', 'SGD', 0.006, 0.99): {'validation_loss': 0.6855544093996286, 'accuracy': 56.25}, ('Model_0', 'SGD', 0.01, 0.99): {'validation_loss': 0.7056859154254198, 'accuracy': 56.25}, ('Model_1', 'Adam', 0.001): {'validation_loss': 0.5741466626059264, 'accuracy': 57.8125}, ('Model_1', 'Adam', 0.003): {'validation_loss': 0.5873547058872646, 'accuracy': 67.1875}, ('Model_1', 'Adam', 0.006): {'validation_loss': 0.6014100266620517, 'accuracy': 67.1875}, ('Model_1', 'Adam', 0.01): {'validation_loss': 0.6930701769888401, 'accuracy': 56.25}, ('Model_1', 'SGD', 0.001, 0.9): {'validation_loss': 0.5691938339732587, 'accuracy': 62.5}, ('Model_1', 'SGD', 0.003, 0.9): {'validation_loss': 0.5331613076559734, 'accuracy': 70.3125}, ('Model_1', 'SGD', 0.006, 0.9): {'validation_loss': 0.593662922095973, 'accuracy': 65.625}, ('Model_1', 'SGD', 0.01, 0.9): {'validation_loss': 0.6010831565363333, 'accuracy': 64.0625}, ('Model_1', 'SGD', 0.001, 0.95): {'validation_loss': 0.6252366346889175, 'accuracy': 60.9375}, ('Model_1', 'SGD', 0.003, 0.95): {'validation_loss': 0.5786969762993976, 'accuracy': 56.25}, ('Model_1', 'SGD', 0.006, 0.95): {'validation_loss': 0.5254538168665022, 'accuracy': 70.3125}, ('Model_1', 'SGD', 0.01, 0.95): {'validation_loss': 0.6871452257037163, 'accuracy': 56.25}, ('Model_1', 'SGD', 0.001, 0.99): {'validation_loss': 0.568125709774904, 'accuracy': 67.1875}, ('Model_1', 'SGD', 0.003, 0.99): {'validation_loss': 0.6923463121056557, 'accuracy': 56.25}, ('Model_1', 'SGD', 0.006, 0.99): {'validation_loss': 0.7168959537521005, 'accuracy': 56.25}, ('Model_1', 'SGD', 0.01, 0.99): {'validation_loss': 0.6906030867248774, 'accuracy': 56.25}, ('Model_2', 'Adam', 0.001): {'validation_loss': 0.6869745563017204, 'accuracy': 62.5}, ('Model_2', 'Adam', 0.003): {'validation_loss': 0.7456315932795405, 'accuracy': 56.25}, ('Model_2', 'Adam', 0.006): {'validation_loss': 0.6911616884171963, 'accuracy': 56.25}, ('Model_2', 'Adam', 0.01): {'validation_loss': 0.6929603293538094, 'accuracy': 56.25}, ('Model_2', 'SGD', 0.001, 0.9): {'validation_loss': 0.6153415632434189, 'accuracy': 67.1875}, ('Model_2', 'SGD', 0.003, 0.9): {'validation_loss': 0.6525177925941534, 'accuracy': 59.375}, ('Model_2', 'SGD', 0.006, 0.9): {'validation_loss': 0.5458518922096118, 'accuracy': 64.0625}, ('Model_2', 'SGD', 0.01, 0.9): {'validation_loss': 0.7310841826256365, 'accuracy': 57.8125}, ('Model_2', 'SGD', 0.001, 0.95): {'validation_loss': 0.5488046548562124, 'accuracy': 59.375}, ('Model_2', 'SGD', 0.003, 0.95): {'validation_loss': 0.7068923271726817, 'accuracy': 59.375}, ('Model_2', 'SGD', 0.006, 0.95): {'validation_loss': 0.6397616993635893, 'accuracy': 68.75}, ('Model_2', 'SGD', 0.01, 0.95): {'validation_loss': 1.03959722770378, 'accuracy': 56.25}, ('Model_2', 'SGD', 0.001, 0.99): {'validation_loss': 0.6440096467267722, 'accuracy': 67.1875}, ('Model_2', 'SGD', 0.003, 0.99): {'validation_loss': 0.688763989135623, 'accuracy': 56.25}, ('Model_2', 'SGD', 0.006, 0.99): {'validation_loss': 0.6914587235078216, 'accuracy': 56.25}, ('Model_2', 'SGD', 0.01, 0.99): {'validation_loss': 43.75, 'accuracy': 56.25}}\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "input_size = 56\n",
    "hidden_size = 128\n",
    "num_epochs = 30\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "results = {}\n",
    "results, accuracys = hyperparameter_tuning(train_dataloader, validation_dataloader, test_dataloader, criterion, num_epochs, device)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Results into a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "models_df = []\n",
    "optimizer_df = []\n",
    "learning_rate_df = []\n",
    "momentum_df = []\n",
    "accuracy_df = []\n",
    "validation_loss_df = []\n",
    "for key,value in results.items():\n",
    "    accuracy_df.append(value['accuracy'])\n",
    "    validation_loss_df.append(value['validation_loss'])\n",
    "    opti = key[1]\n",
    "    models_df.append(key[0])\n",
    "    optimizer_df.append(opti)\n",
    "    learning_rate_df.append(key[2])\n",
    "    if opti == 'SGD':\n",
    "        momentum_df.append(key[3])\n",
    "    else:\n",
    "        momentum_df.append(None)\n",
    "        \n",
    "df['Model'] = models_df\n",
    "df['Optimizer'] = optimizer_df\n",
    "df['Learning Rate'] = learning_rate_df\n",
    "df['Momentum'] = momentum_df\n",
    "df['Validation Loss'] = validation_loss_df\n",
    "df['Accuracy'] = accuracy_df\n",
    "df.to_csv('Results/FNN_BP_PHQ_9.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Do the same for the MH_PHQ_S Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "ID_1          40\n",
      "ID_2          40\n",
      "group_id      40\n",
      "SEX           40\n",
      "AGE           40\n",
      "              ..\n",
      "FEATURE_51    40\n",
      "FEATURE_52    40\n",
      "FEATURE_53    40\n",
      "FEATURE_54    40\n",
      "FEATURE_55    40\n",
      "Length: 65, dtype: int64\n",
      "1.0\n",
      "ID_1          40\n",
      "ID_2          40\n",
      "group_id      40\n",
      "SEX           40\n",
      "AGE           40\n",
      "              ..\n",
      "FEATURE_51    40\n",
      "FEATURE_52    40\n",
      "FEATURE_53    40\n",
      "FEATURE_54    40\n",
      "FEATURE_55    40\n",
      "Length: 65, dtype: int64\n",
      "2.0\n",
      "ID_1          40\n",
      "ID_2          40\n",
      "group_id      40\n",
      "SEX           40\n",
      "AGE           40\n",
      "              ..\n",
      "FEATURE_51    40\n",
      "FEATURE_52    40\n",
      "FEATURE_53    40\n",
      "FEATURE_54    40\n",
      "FEATURE_55    40\n",
      "Length: 65, dtype: int64\n",
      "3.0\n",
      "ID_1          40\n",
      "ID_2          40\n",
      "group_id      40\n",
      "SEX           40\n",
      "AGE           40\n",
      "              ..\n",
      "FEATURE_51    40\n",
      "FEATURE_52    40\n",
      "FEATURE_53    40\n",
      "FEATURE_54    40\n",
      "FEATURE_55    40\n",
      "Length: 65, dtype: int64\n",
      "4.0\n",
      "ID_1          40\n",
      "ID_2          40\n",
      "group_id      40\n",
      "SEX           40\n",
      "AGE           40\n",
      "              ..\n",
      "FEATURE_51    40\n",
      "FEATURE_52    40\n",
      "FEATURE_53    40\n",
      "FEATURE_54    40\n",
      "FEATURE_55    40\n",
      "Length: 65, dtype: int64\n",
      "5.0\n",
      "ID_1          40\n",
      "ID_2          40\n",
      "group_id      40\n",
      "SEX           40\n",
      "AGE           40\n",
      "              ..\n",
      "FEATURE_51    40\n",
      "FEATURE_52    40\n",
      "FEATURE_53    40\n",
      "FEATURE_54    40\n",
      "FEATURE_55    40\n",
      "Length: 65, dtype: int64\n",
      "6.0\n",
      "ID_1          40\n",
      "ID_2          40\n",
      "group_id      40\n",
      "SEX           40\n",
      "AGE           40\n",
      "              ..\n",
      "FEATURE_51    40\n",
      "FEATURE_52    40\n",
      "FEATURE_53    40\n",
      "FEATURE_54    40\n",
      "FEATURE_55    40\n",
      "Length: 65, dtype: int64\n",
      "7.0\n",
      "ID_1          40\n",
      "ID_2          40\n",
      "group_id      40\n",
      "SEX           40\n",
      "AGE           40\n",
      "              ..\n",
      "FEATURE_51    40\n",
      "FEATURE_52    40\n",
      "FEATURE_53    40\n",
      "FEATURE_54    40\n",
      "FEATURE_55    40\n",
      "Length: 65, dtype: int64\n",
      "8.0\n",
      "ID_1          40\n",
      "ID_2          40\n",
      "group_id      40\n",
      "SEX           40\n",
      "AGE           40\n",
      "              ..\n",
      "FEATURE_51    40\n",
      "FEATURE_52    40\n",
      "FEATURE_53    40\n",
      "FEATURE_54    40\n",
      "FEATURE_55    40\n",
      "Length: 65, dtype: int64\n",
      "9.0\n",
      "ID_1          40\n",
      "ID_2          40\n",
      "group_id      40\n",
      "SEX           40\n",
      "AGE           40\n",
      "              ..\n",
      "FEATURE_51    40\n",
      "FEATURE_52    40\n",
      "FEATURE_53    40\n",
      "FEATURE_54    40\n",
      "FEATURE_55    40\n",
      "Length: 65, dtype: int64\n",
      "10.0\n",
      "ID_1          40\n",
      "ID_2          40\n",
      "group_id      40\n",
      "SEX           40\n",
      "AGE           40\n",
      "              ..\n",
      "FEATURE_51    40\n",
      "FEATURE_52    40\n",
      "FEATURE_53    40\n",
      "FEATURE_54    40\n",
      "FEATURE_55    40\n",
      "Length: 65, dtype: int64\n",
      "11.0\n",
      "ID_1          40\n",
      "ID_2          40\n",
      "group_id      40\n",
      "SEX           40\n",
      "AGE           40\n",
      "              ..\n",
      "FEATURE_51    40\n",
      "FEATURE_52    40\n",
      "FEATURE_53    40\n",
      "FEATURE_54    40\n",
      "FEATURE_55    40\n",
      "Length: 65, dtype: int64\n",
      "12.0\n",
      "ID_1          40\n",
      "ID_2          40\n",
      "group_id      40\n",
      "SEX           40\n",
      "AGE           40\n",
      "              ..\n",
      "FEATURE_51    40\n",
      "FEATURE_52    40\n",
      "FEATURE_53    40\n",
      "FEATURE_54    40\n",
      "FEATURE_55    40\n",
      "Length: 65, dtype: int64\n",
      "13.0\n",
      "ID_1          40\n",
      "ID_2          40\n",
      "group_id      40\n",
      "SEX           40\n",
      "AGE           40\n",
      "              ..\n",
      "FEATURE_51    40\n",
      "FEATURE_52    40\n",
      "FEATURE_53    40\n",
      "FEATURE_54    40\n",
      "FEATURE_55    40\n",
      "Length: 65, dtype: int64\n",
      "14.0\n",
      "ID_1          40\n",
      "ID_2          40\n",
      "group_id      40\n",
      "SEX           40\n",
      "AGE           40\n",
      "              ..\n",
      "FEATURE_51    40\n",
      "FEATURE_52    40\n",
      "FEATURE_53    40\n",
      "FEATURE_54    40\n",
      "FEATURE_55    40\n",
      "Length: 65, dtype: int64\n",
      "15.0\n",
      "ID_1          40\n",
      "ID_2          40\n",
      "group_id      40\n",
      "SEX           40\n",
      "AGE           40\n",
      "              ..\n",
      "FEATURE_51    40\n",
      "FEATURE_52    40\n",
      "FEATURE_53    40\n",
      "FEATURE_54    40\n",
      "FEATURE_55    40\n",
      "Length: 65, dtype: int64\n",
      "16.0\n",
      "ID_1          40\n",
      "ID_2          40\n",
      "group_id      40\n",
      "SEX           40\n",
      "AGE           40\n",
      "              ..\n",
      "FEATURE_51    40\n",
      "FEATURE_52    40\n",
      "FEATURE_53    40\n",
      "FEATURE_54    40\n",
      "FEATURE_55    40\n",
      "Length: 65, dtype: int64\n",
      "17.0\n",
      "ID_1          40\n",
      "ID_2          40\n",
      "group_id      40\n",
      "SEX           40\n",
      "AGE           40\n",
      "              ..\n",
      "FEATURE_51    40\n",
      "FEATURE_52    40\n",
      "FEATURE_53    40\n",
      "FEATURE_54    40\n",
      "FEATURE_55    40\n",
      "Length: 65, dtype: int64\n",
      "18.0\n",
      "ID_1          40\n",
      "ID_2          40\n",
      "group_id      40\n",
      "SEX           40\n",
      "AGE           40\n",
      "              ..\n",
      "FEATURE_51    40\n",
      "FEATURE_52    40\n",
      "FEATURE_53    40\n",
      "FEATURE_54    40\n",
      "FEATURE_55    40\n",
      "Length: 65, dtype: int64\n",
      "19.0\n",
      "ID_1          40\n",
      "ID_2          40\n",
      "group_id      40\n",
      "SEX           40\n",
      "AGE           40\n",
      "              ..\n",
      "FEATURE_51    40\n",
      "FEATURE_52    40\n",
      "FEATURE_53    40\n",
      "FEATURE_54    40\n",
      "FEATURE_55    40\n",
      "Length: 65, dtype: int64\n",
      "20.0\n",
      "ID_1          40\n",
      "ID_2          40\n",
      "group_id      40\n",
      "SEX           40\n",
      "AGE           40\n",
      "              ..\n",
      "FEATURE_51    40\n",
      "FEATURE_52    40\n",
      "FEATURE_53    40\n",
      "FEATURE_54    40\n",
      "FEATURE_55    40\n",
      "Length: 65, dtype: int64\n",
      "21.0\n",
      "ID_1          40\n",
      "ID_2          40\n",
      "group_id      40\n",
      "SEX           40\n",
      "AGE           40\n",
      "              ..\n",
      "FEATURE_51    40\n",
      "FEATURE_52    40\n",
      "FEATURE_53    40\n",
      "FEATURE_54    40\n",
      "FEATURE_55    40\n",
      "Length: 65, dtype: int64\n",
      "22.0\n",
      "ID_1          40\n",
      "ID_2          40\n",
      "group_id      40\n",
      "SEX           40\n",
      "AGE           40\n",
      "              ..\n",
      "FEATURE_51    40\n",
      "FEATURE_52    40\n",
      "FEATURE_53    40\n",
      "FEATURE_54    40\n",
      "FEATURE_55    40\n",
      "Length: 65, dtype: int64\n",
      "23.0\n",
      "ID_1          40\n",
      "ID_2          40\n",
      "group_id      40\n",
      "SEX           40\n",
      "AGE           40\n",
      "              ..\n",
      "FEATURE_51    40\n",
      "FEATURE_52    40\n",
      "FEATURE_53    40\n",
      "FEATURE_54    40\n",
      "FEATURE_55    40\n",
      "Length: 65, dtype: int64\n",
      "24.0\n",
      "ID_1          40\n",
      "ID_2          40\n",
      "group_id      40\n",
      "SEX           40\n",
      "AGE           40\n",
      "              ..\n",
      "FEATURE_51    40\n",
      "FEATURE_52    40\n",
      "FEATURE_53    40\n",
      "FEATURE_54    40\n",
      "FEATURE_55    40\n",
      "Length: 65, dtype: int64\n",
      "25.0\n",
      "ID_1          40\n",
      "ID_2          40\n",
      "group_id      40\n",
      "SEX           40\n",
      "AGE           40\n",
      "              ..\n",
      "FEATURE_51    40\n",
      "FEATURE_52    40\n",
      "FEATURE_53    40\n",
      "FEATURE_54    40\n",
      "FEATURE_55    40\n",
      "Length: 65, dtype: int64\n",
      "26.0\n",
      "ID_1          40\n",
      "ID_2          40\n",
      "group_id      40\n",
      "SEX           40\n",
      "AGE           40\n",
      "              ..\n",
      "FEATURE_51    40\n",
      "FEATURE_52    40\n",
      "FEATURE_53    40\n",
      "FEATURE_54    40\n",
      "FEATURE_55    40\n",
      "Length: 65, dtype: int64\n",
      "27.0\n",
      "ID_1          40\n",
      "ID_2          40\n",
      "group_id      40\n",
      "SEX           40\n",
      "AGE           40\n",
      "              ..\n",
      "FEATURE_51    40\n",
      "FEATURE_52    40\n",
      "FEATURE_53    40\n",
      "FEATURE_54    40\n",
      "FEATURE_55    40\n",
      "Length: 65, dtype: int64\n",
      "---Number of Non-Depression and Depression---\n",
      "600 520\n",
      "torch.Size([806, 56]) torch.Size([806]) torch.Size([202, 56]) torch.Size([202]) torch.Size([112, 56]) torch.Size([112])\n"
     ]
    }
   ],
   "source": [
    "df2= pd.read_csv('../data/Threshold_15_Operator_-_Depressionfeature_MH_PHQ_S_PercentofDataset_100.csv')\n",
    "print_information(df2)\n",
    "# 0.9 train, 0.1 test\n",
    "train_df2, test_df2 = train_test_split(df2, test_size=0.1, random_state=42)\n",
    "# 0.8 train, 0.2 validation\n",
    "train_df2, validation_df2 = train_test_split(train_df2, train_size=0.8, random_state=42)\n",
    "\n",
    "train_features, train_targets = df_to_tensor(train_df2,features_column='FEATURES', target_col='Depression')\n",
    "validation_features, validation_targets = df_to_tensor(validation_df2, features_column='FEATURES', target_col='Depression')\n",
    "test_features, test_targets = df_to_tensor(test_df2, features_column='FEATURES', target_col='Depression')\n",
    "\n",
    "print(train_features.shape, train_targets.shape, validation_features.shape, validation_targets.shape, test_features.shape, test_targets.shape)\n",
    "#print(train_features.shape, train_targets.shape, test_features.shape, test_targets.shape)\n",
    "\n",
    "train_dataset = CustomDataset(train_features, train_targets)\n",
    "validation_dataset = CustomDataset(validation_features, validation_targets)\n",
    "test_dataset = CustomDataset(test_features, test_targets)\n",
    "\n",
    "train_dataloader2 = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "validation_dataloader2 = DataLoader(validation_dataset, batch_size=2, shuffle=False)\n",
    "test_dataloader2 = DataLoader(test_dataset, batch_size=2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6766, Accuracy: 55.36%\n",
      "Model: 1 is being trained with optimizer: Adam and learning rate: 0.001 and Model_0\n",
      "Loss: 0.6550, Accuracy: 64.29%\n",
      "Model: 2 is being trained with optimizer: Adam and learning rate: 0.003 and Model_0\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6652, Accuracy: 60.71%\n",
      "Model: 3 is being trained with optimizer: Adam and learning rate: 0.006 and Model_0\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6899, Accuracy: 58.04%\n",
      "Model: 4 is being trained with optimizer: Adam and learning rate: 0.01 and Model_0\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6464, Accuracy: 64.29%\n",
      "Model: 5 is being trained with optimizer: SGD and learning rate: 0.001 and Model_0\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6675, Accuracy: 61.61%\n",
      "Model: 6 is being trained with optimizer: SGD and learning rate: 0.003 and Model_0\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6727, Accuracy: 64.29%\n",
      "Model: 7 is being trained with optimizer: SGD and learning rate: 0.006 and Model_0\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6745, Accuracy: 58.04%\n",
      "Model: 8 is being trained with optimizer: SGD and learning rate: 0.01 and Model_0\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6477, Accuracy: 64.29%\n",
      "Model: 9 is being trained with optimizer: SGD and learning rate: 0.001 and Model_0\n",
      "Loss: 0.6791, Accuracy: 61.61%\n",
      "Model: 10 is being trained with optimizer: SGD and learning rate: 0.003 and Model_0\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6931, Accuracy: 58.04%\n",
      "Model: 11 is being trained with optimizer: SGD and learning rate: 0.006 and Model_0\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.7009, Accuracy: 41.96%\n",
      "Model: 12 is being trained with optimizer: SGD and learning rate: 0.01 and Model_0\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6820, Accuracy: 58.04%\n",
      "Model: 13 is being trained with optimizer: SGD and learning rate: 0.001 and Model_0\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6992, Accuracy: 41.96%\n",
      "Model: 14 is being trained with optimizer: SGD and learning rate: 0.003 and Model_0\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6892, Accuracy: 58.04%\n",
      "Model: 15 is being trained with optimizer: SGD and learning rate: 0.006 and Model_0\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.7141, Accuracy: 41.96%\n",
      "Model: 16 is being trained with optimizer: SGD and learning rate: 0.01 and Model_0\n",
      "Loss: 0.6719, Accuracy: 62.50%\n",
      "Model: 17 is being trained with optimizer: Adam and learning rate: 0.001 and Model_1\n",
      "Loss: 0.7015, Accuracy: 60.71%\n",
      "Model: 18 is being trained with optimizer: Adam and learning rate: 0.003 and Model_1\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6876, Accuracy: 58.04%\n",
      "Model: 19 is being trained with optimizer: Adam and learning rate: 0.006 and Model_1\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6855, Accuracy: 58.04%\n",
      "Model: 20 is being trained with optimizer: Adam and learning rate: 0.01 and Model_1\n",
      "Loss: 0.6333, Accuracy: 64.29%\n",
      "Model: 21 is being trained with optimizer: SGD and learning rate: 0.001 and Model_1\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6892, Accuracy: 62.50%\n",
      "Model: 22 is being trained with optimizer: SGD and learning rate: 0.003 and Model_1\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6427, Accuracy: 64.29%\n",
      "Model: 23 is being trained with optimizer: SGD and learning rate: 0.006 and Model_1\n",
      "Loss: 0.6509, Accuracy: 59.82%\n",
      "Model: 24 is being trained with optimizer: SGD and learning rate: 0.01 and Model_1\n",
      "Loss: 0.6428, Accuracy: 64.29%\n",
      "Model: 25 is being trained with optimizer: SGD and learning rate: 0.001 and Model_1\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6655, Accuracy: 58.04%\n",
      "Model: 26 is being trained with optimizer: SGD and learning rate: 0.003 and Model_1\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6913, Accuracy: 58.04%\n",
      "Model: 27 is being trained with optimizer: SGD and learning rate: 0.006 and Model_1\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6965, Accuracy: 46.43%\n",
      "Model: 28 is being trained with optimizer: SGD and learning rate: 0.01 and Model_1\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6777, Accuracy: 60.71%\n",
      "Model: 29 is being trained with optimizer: SGD and learning rate: 0.001 and Model_1\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6843, Accuracy: 58.04%\n",
      "Model: 30 is being trained with optimizer: SGD and learning rate: 0.003 and Model_1\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.7116, Accuracy: 41.96%\n",
      "Model: 31 is being trained with optimizer: SGD and learning rate: 0.006 and Model_1\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.7491, Accuracy: 41.96%\n",
      "Model: 32 is being trained with optimizer: SGD and learning rate: 0.01 and Model_1\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6540, Accuracy: 64.29%\n",
      "Model: 33 is being trained with optimizer: Adam and learning rate: 0.001 and Model_2\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6834, Accuracy: 58.04%\n",
      "Model: 34 is being trained with optimizer: Adam and learning rate: 0.003 and Model_2\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.7115, Accuracy: 41.96%\n",
      "Model: 35 is being trained with optimizer: Adam and learning rate: 0.006 and Model_2\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.7776, Accuracy: 41.96%\n",
      "Model: 36 is being trained with optimizer: Adam and learning rate: 0.01 and Model_2\n",
      "Loss: 0.6381, Accuracy: 66.07%\n",
      "Model: 37 is being trained with optimizer: SGD and learning rate: 0.001 and Model_2\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6474, Accuracy: 66.07%\n",
      "Model: 38 is being trained with optimizer: SGD and learning rate: 0.003 and Model_2\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6612, Accuracy: 64.29%\n",
      "Model: 39 is being trained with optimizer: SGD and learning rate: 0.006 and Model_2\n",
      "Loss: 0.6581, Accuracy: 64.29%\n",
      "Model: 40 is being trained with optimizer: SGD and learning rate: 0.01 and Model_2\n",
      "Loss: 0.6665, Accuracy: 64.29%\n",
      "Model: 41 is being trained with optimizer: SGD and learning rate: 0.001 and Model_2\n",
      "Loss: 0.6545, Accuracy: 62.50%\n",
      "Model: 42 is being trained with optimizer: SGD and learning rate: 0.003 and Model_2\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6602, Accuracy: 61.61%\n",
      "Model: 43 is being trained with optimizer: SGD and learning rate: 0.006 and Model_2\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6754, Accuracy: 60.71%\n",
      "Model: 44 is being trained with optimizer: SGD and learning rate: 0.01 and Model_2\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.6636, Accuracy: 65.18%\n",
      "Model: 45 is being trained with optimizer: SGD and learning rate: 0.001 and Model_2\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.7910, Accuracy: 41.96%\n",
      "Model: 46 is being trained with optimizer: SGD and learning rate: 0.003 and Model_2\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 1.1077, Accuracy: 41.96%\n",
      "Model: 47 is being trained with optimizer: SGD and learning rate: 0.006 and Model_2\n",
      "Validation loss did not improve for 10 epochs. Early stopping...\n",
      "Loss: 0.7448, Accuracy: 58.04%\n",
      "Model: 48 is being trained with optimizer: SGD and learning rate: 0.01 and Model_2\n",
      "{('Model_0', 'Adam', 0.001): {'validation_loss': 0.6765981444290706, 'accuracy': 55.357142857142854}, ('Model_0', 'Adam', 0.003): {'validation_loss': 0.655037601611444, 'accuracy': 64.28571428571429}, ('Model_0', 'Adam', 0.006): {'validation_loss': 0.6651842503675393, 'accuracy': 60.714285714285715}, ('Model_0', 'Adam', 0.01): {'validation_loss': 0.6899045067174094, 'accuracy': 58.035714285714285}, ('Model_0', 'SGD', 0.001, 0.9): {'validation_loss': 0.6463754171771663, 'accuracy': 64.28571428571429}, ('Model_0', 'SGD', 0.003, 0.9): {'validation_loss': 0.6674537139811686, 'accuracy': 61.607142857142854}, ('Model_0', 'SGD', 0.006, 0.9): {'validation_loss': 0.6727156745535987, 'accuracy': 64.28571428571429}, ('Model_0', 'SGD', 0.01, 0.9): {'validation_loss': 0.6745081421520028, 'accuracy': 58.035714285714285}, ('Model_0', 'SGD', 0.001, 0.95): {'validation_loss': 0.6476901639252901, 'accuracy': 64.28571428571429}, ('Model_0', 'SGD', 0.003, 0.95): {'validation_loss': 0.679093223198184, 'accuracy': 61.607142857142854}, ('Model_0', 'SGD', 0.006, 0.95): {'validation_loss': 0.6930787648473468, 'accuracy': 58.035714285714285}, ('Model_0', 'SGD', 0.01, 0.95): {'validation_loss': 0.7008508411901337, 'accuracy': 41.964285714285715}, ('Model_0', 'SGD', 0.001, 0.99): {'validation_loss': 0.6819901221564838, 'accuracy': 58.035714285714285}, ('Model_0', 'SGD', 0.003, 0.99): {'validation_loss': 0.6991974722061839, 'accuracy': 41.964285714285715}, ('Model_0', 'SGD', 0.006, 0.99): {'validation_loss': 0.6892107799649239, 'accuracy': 58.035714285714285}, ('Model_0', 'SGD', 0.01, 0.99): {'validation_loss': 0.7140633964112827, 'accuracy': 41.964285714285715}, ('Model_1', 'Adam', 0.001): {'validation_loss': 0.6718876028566488, 'accuracy': 62.5}, ('Model_1', 'Adam', 0.003): {'validation_loss': 0.7015178448387555, 'accuracy': 60.714285714285715}, ('Model_1', 'Adam', 0.006): {'validation_loss': 0.6875598547714097, 'accuracy': 58.035714285714285}, ('Model_1', 'Adam', 0.01): {'validation_loss': 0.6855241347636495, 'accuracy': 58.035714285714285}, ('Model_1', 'SGD', 0.001, 0.9): {'validation_loss': 0.6333391331136227, 'accuracy': 64.28571428571429}, ('Model_1', 'SGD', 0.003, 0.9): {'validation_loss': 0.6891952602724943, 'accuracy': 62.5}, ('Model_1', 'SGD', 0.006, 0.9): {'validation_loss': 0.6427022005830493, 'accuracy': 64.28571428571429}, ('Model_1', 'SGD', 0.01, 0.9): {'validation_loss': 0.6509449072182178, 'accuracy': 59.82142857142857}, ('Model_1', 'SGD', 0.001, 0.95): {'validation_loss': 0.6427995764783451, 'accuracy': 64.28571428571429}, ('Model_1', 'SGD', 0.003, 0.95): {'validation_loss': 0.6655159800180367, 'accuracy': 58.035714285714285}, ('Model_1', 'SGD', 0.006, 0.95): {'validation_loss': 0.6913334844367844, 'accuracy': 58.035714285714285}, ('Model_1', 'SGD', 0.01, 0.95): {'validation_loss': 0.6965493378894669, 'accuracy': 46.42857142857143}, ('Model_1', 'SGD', 0.001, 0.99): {'validation_loss': 0.6776922919920513, 'accuracy': 60.714285714285715}, ('Model_1', 'SGD', 0.003, 0.99): {'validation_loss': 0.6842875342283931, 'accuracy': 58.035714285714285}, ('Model_1', 'SGD', 0.006, 0.99): {'validation_loss': 0.7116321005991527, 'accuracy': 41.964285714285715}, ('Model_1', 'SGD', 0.01, 0.99): {'validation_loss': 0.7490798969353948, 'accuracy': 41.964285714285715}, ('Model_2', 'Adam', 0.001): {'validation_loss': 0.654042045452765, 'accuracy': 64.28571428571429}, ('Model_2', 'Adam', 0.003): {'validation_loss': 0.6834199205040932, 'accuracy': 58.035714285714285}, ('Model_2', 'Adam', 0.006): {'validation_loss': 0.7114632448979786, 'accuracy': 41.964285714285715}, ('Model_2', 'Adam', 0.01): {'validation_loss': 0.7776473356144769, 'accuracy': 41.964285714285715}, ('Model_2', 'SGD', 0.001, 0.9): {'validation_loss': 0.6381280209336962, 'accuracy': 66.07142857142857}, ('Model_2', 'SGD', 0.003, 0.9): {'validation_loss': 0.6474333751414504, 'accuracy': 66.07142857142857}, ('Model_2', 'SGD', 0.006, 0.9): {'validation_loss': 0.6611959239734071, 'accuracy': 64.28571428571429}, ('Model_2', 'SGD', 0.01, 0.9): {'validation_loss': 0.6581293610589845, 'accuracy': 64.28571428571429}, ('Model_2', 'SGD', 0.001, 0.95): {'validation_loss': 0.666463537673865, 'accuracy': 64.28571428571429}, ('Model_2', 'SGD', 0.003, 0.95): {'validation_loss': 0.6545425632170269, 'accuracy': 62.5}, ('Model_2', 'SGD', 0.006, 0.95): {'validation_loss': 0.6601768923657281, 'accuracy': 61.607142857142854}, ('Model_2', 'SGD', 0.01, 0.95): {'validation_loss': 0.6754153871110508, 'accuracy': 60.714285714285715}, ('Model_2', 'SGD', 0.001, 0.99): {'validation_loss': 0.6635862807078021, 'accuracy': 65.17857142857143}, ('Model_2', 'SGD', 0.003, 0.99): {'validation_loss': 0.7909794950059482, 'accuracy': 41.964285714285715}, ('Model_2', 'SGD', 0.006, 0.99): {'validation_loss': 1.1076871130083288, 'accuracy': 41.964285714285715}, ('Model_2', 'SGD', 0.01, 0.99): {'validation_loss': 0.7448000258633068, 'accuracy': 58.035714285714285}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Configuration\n",
    "input_size = 56\n",
    "hidden_size = 128\n",
    "num_epochs = 30\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "results = {}\n",
    "results, accuracys = cross_validation(train_dataloader2, validation_dataloader2, test_dataloader2, criterion, num_epochs, device)\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "models_df = []\n",
    "optimizer_df = []\n",
    "learning_rate_df = []\n",
    "momentum_df = []\n",
    "accuracy_df = []\n",
    "validation_loss_df = []\n",
    "for key,value in results.items():\n",
    "    accuracy_df.append(value['accuracy'])\n",
    "    validation_loss_df.append(value['validation_loss'])\n",
    "    opti = key[1]\n",
    "    models_df.append(key[0])\n",
    "    optimizer_df.append(opti)\n",
    "    learning_rate_df.append(key[2])\n",
    "    if opti == 'SGD':\n",
    "        momentum_df.append(key[3])\n",
    "    else:\n",
    "        momentum_df.append(None)\n",
    "        \n",
    "df['Model'] = models_df\n",
    "df['Optimizer'] = optimizer_df\n",
    "df['Learning Rate'] = learning_rate_df\n",
    "df['Momentum'] = momentum_df\n",
    "df['Validation Loss'] = validation_loss_df\n",
    "df['Accuracy'] = accuracy_df\n",
    "df.to_csv('Results/FNN_MH_PHQ_S.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the two dataframes created and compare the performances of the models on dataset BP_PHQ_9 and MH_PHQ_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model               Model_1\n",
      "Optimizer               SGD\n",
      "Learning Rate         0.003\n",
      "Momentum                0.9\n",
      "Validation Loss    0.533161\n",
      "Accuracy            70.3125\n",
      "Name: 21, dtype: object\n",
      "Model                Model_2\n",
      "Optimizer                SGD\n",
      "Learning Rate          0.001\n",
      "Momentum                 0.9\n",
      "Validation Loss     0.638128\n",
      "Accuracy           66.071429\n",
      "Name: 36, dtype: object\n"
     ]
    }
   ],
   "source": [
    "bp_phq_9 = pd.read_csv('Results/FNN_BP_PHQ_9.csv')\n",
    "mh_phq_s = pd.read_csv('Results/FNN_MH_PHQ_S.csv')\n",
    "\n",
    "max_index_phq9 = bp_phq_9['Accuracy'].idxmax()\n",
    "max_index_mh_phq_s = mh_phq_s['Accuracy'].idxmax()\n",
    "\n",
    "print(bp_phq_9.loc[max_index_phq9])\n",
    "print(mh_phq_s.loc[max_index_mh_phq_s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Now train the best performing hyperparameters on a larger epoch number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset BP_PHQ_9 Hyperparameters: Learning Rate: 0.003, Optimizer: SGD, Momentum: 0.9,  Model: Model_1\n",
    "- Dataset MH_PHQ_S Hyperparameters: Learning Rate: 0.001, Optimizer: SGD, Momentum: 0.9, Model: Model_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for the BP_PHQ_9 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Step [100/230], Loss: 0.6968\n",
      "Epoch [1/30], Step [200/230], Loss: 0.6626\n",
      "Epoch [2/30], Step [100/230], Loss: 0.6531\n",
      "Epoch [2/30], Step [200/230], Loss: 0.6638\n",
      "Epoch [3/30], Step [100/230], Loss: 0.6616\n",
      "Epoch [3/30], Step [200/230], Loss: 0.6170\n",
      "Epoch [4/30], Step [100/230], Loss: 0.6176\n",
      "Epoch [4/30], Step [200/230], Loss: 0.6222\n",
      "Epoch [5/30], Step [100/230], Loss: 0.5859\n",
      "Epoch [5/30], Step [200/230], Loss: 0.5573\n",
      "Epoch [6/30], Step [100/230], Loss: 0.5610\n",
      "Epoch [6/30], Step [200/230], Loss: 0.5154\n",
      "Epoch [7/30], Step [100/230], Loss: 0.5517\n",
      "Epoch [7/30], Step [200/230], Loss: 0.5019\n",
      "Epoch [8/30], Step [100/230], Loss: 0.5512\n",
      "Epoch [8/30], Step [200/230], Loss: 0.4905\n",
      "Epoch [9/30], Step [100/230], Loss: 0.5220\n",
      "Epoch [9/30], Step [200/230], Loss: 0.5084\n",
      "Epoch [10/30], Step [100/230], Loss: 0.5479\n",
      "Epoch [10/30], Step [200/230], Loss: 0.4942\n",
      "Epoch [11/30], Step [100/230], Loss: 0.4791\n",
      "Epoch [11/30], Step [200/230], Loss: 0.5368\n",
      "Epoch [12/30], Step [100/230], Loss: 0.4942\n",
      "Epoch [12/30], Step [200/230], Loss: 0.5793\n",
      "Epoch [13/30], Step [100/230], Loss: 0.5360\n",
      "Epoch [13/30], Step [200/230], Loss: 0.4385\n",
      "Epoch [14/30], Step [100/230], Loss: 0.4749\n",
      "Epoch [14/30], Step [200/230], Loss: 0.4968\n",
      "Epoch [15/30], Step [100/230], Loss: 0.4721\n",
      "Epoch [15/30], Step [200/230], Loss: 0.4863\n",
      "Epoch [16/30], Step [100/230], Loss: 0.4920\n",
      "Epoch [16/30], Step [200/230], Loss: 0.4911\n",
      "Epoch [17/30], Step [100/230], Loss: 0.5099\n",
      "Epoch [17/30], Step [200/230], Loss: 0.4377\n",
      "Epoch [18/30], Step [100/230], Loss: 0.5315\n",
      "Epoch [18/30], Step [200/230], Loss: 0.4195\n",
      "Epoch [19/30], Step [100/230], Loss: 0.5066\n",
      "Epoch [19/30], Step [200/230], Loss: 0.4461\n",
      "Epoch [20/30], Step [100/230], Loss: 0.5139\n",
      "Epoch [20/30], Step [200/230], Loss: 0.4468\n",
      "Epoch [21/30], Step [100/230], Loss: 0.4458\n",
      "Epoch [21/30], Step [200/230], Loss: 0.4732\n",
      "Epoch [22/30], Step [100/230], Loss: 0.4533\n",
      "Epoch [22/30], Step [200/230], Loss: 0.4334\n",
      "Epoch [23/30], Step [100/230], Loss: 0.4439\n",
      "Epoch [23/30], Step [200/230], Loss: 0.4652\n",
      "Epoch [24/30], Step [100/230], Loss: 0.4884\n",
      "Epoch [24/30], Step [200/230], Loss: 0.4849\n",
      "Epoch [25/30], Step [100/230], Loss: 0.4361\n",
      "Epoch [25/30], Step [200/230], Loss: 0.5153\n",
      "Epoch [26/30], Step [100/230], Loss: 0.4584\n",
      "Epoch [26/30], Step [200/230], Loss: 0.5069\n",
      "Epoch [27/30], Step [100/230], Loss: 0.4885\n",
      "Epoch [27/30], Step [200/230], Loss: 0.4328\n",
      "Epoch [28/30], Step [100/230], Loss: 0.4294\n",
      "Epoch [28/30], Step [200/230], Loss: 0.4726\n",
      "Epoch [29/30], Step [100/230], Loss: 0.4314\n",
      "Epoch [29/30], Step [200/230], Loss: 0.4872\n",
      "Epoch [30/30], Step [100/230], Loss: 0.4771\n",
      "Epoch [30/30], Step [200/230], Loss: 0.4190\n",
      "Loss: 0.5124, Accuracy: 73.44%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5123844356276095, 73.4375)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration\n",
    "input_size = 56\n",
    "hidden_size = 128\n",
    "num_epochs = 30\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize the model, criterion, and optimizer\n",
    "model = Depression_Classifier_v_1(input_size, hidden_size).to(device)\n",
    "#criterion = nn.BCEWithLogitsLoss()  # Combines sigmoid and binary cross-entropy loss\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
    "optimizers = ['Adam', 'SGD']\n",
    "train_model(model, train_dataloader, criterion, optimizer, num_epochs, device)\n",
    "evaluate_model(model, test_dataloader, criterion, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'Models/BP_PHQ_9.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train for the MH_PHQ_S Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Step [100/403], Loss: 0.6953\n",
      "Epoch [1/30], Step [200/403], Loss: 0.6952\n",
      "Epoch [1/30], Step [300/403], Loss: 0.6865\n",
      "Epoch [1/30], Step [400/403], Loss: 0.6907\n",
      "Epoch [2/30], Step [100/403], Loss: 0.6946\n",
      "Epoch [2/30], Step [200/403], Loss: 0.6934\n",
      "Epoch [2/30], Step [300/403], Loss: 0.6917\n",
      "Epoch [2/30], Step [400/403], Loss: 0.6875\n",
      "Epoch [3/30], Step [100/403], Loss: 0.6914\n",
      "Epoch [3/30], Step [200/403], Loss: 0.6878\n",
      "Epoch [3/30], Step [300/403], Loss: 0.6950\n",
      "Epoch [3/30], Step [400/403], Loss: 0.6805\n",
      "Epoch [4/30], Step [100/403], Loss: 0.6897\n",
      "Epoch [4/30], Step [200/403], Loss: 0.6802\n",
      "Epoch [4/30], Step [300/403], Loss: 0.7002\n",
      "Epoch [4/30], Step [400/403], Loss: 0.6715\n",
      "Epoch [5/30], Step [100/403], Loss: 0.6787\n",
      "Epoch [5/30], Step [200/403], Loss: 0.6704\n",
      "Epoch [5/30], Step [300/403], Loss: 0.7027\n",
      "Epoch [5/30], Step [400/403], Loss: 0.6837\n",
      "Epoch [6/30], Step [100/403], Loss: 0.6706\n",
      "Epoch [6/30], Step [200/403], Loss: 0.6891\n",
      "Epoch [6/30], Step [300/403], Loss: 0.6793\n",
      "Epoch [6/30], Step [400/403], Loss: 0.6854\n",
      "Epoch [7/30], Step [100/403], Loss: 0.6715\n",
      "Epoch [7/30], Step [200/403], Loss: 0.6557\n",
      "Epoch [7/30], Step [300/403], Loss: 0.6777\n",
      "Epoch [7/30], Step [400/403], Loss: 0.6937\n",
      "Epoch [8/30], Step [100/403], Loss: 0.6711\n",
      "Epoch [8/30], Step [200/403], Loss: 0.6710\n",
      "Epoch [8/30], Step [300/403], Loss: 0.6761\n",
      "Epoch [8/30], Step [400/403], Loss: 0.6833\n",
      "Epoch [9/30], Step [100/403], Loss: 0.6690\n",
      "Epoch [9/30], Step [200/403], Loss: 0.6705\n",
      "Epoch [9/30], Step [300/403], Loss: 0.6856\n",
      "Epoch [9/30], Step [400/403], Loss: 0.6668\n",
      "Epoch [10/30], Step [100/403], Loss: 0.6692\n",
      "Epoch [10/30], Step [200/403], Loss: 0.6855\n",
      "Epoch [10/30], Step [300/403], Loss: 0.6545\n",
      "Epoch [10/30], Step [400/403], Loss: 0.6704\n",
      "Epoch [11/30], Step [100/403], Loss: 0.6653\n",
      "Epoch [11/30], Step [200/403], Loss: 0.6640\n",
      "Epoch [11/30], Step [300/403], Loss: 0.6681\n",
      "Epoch [11/30], Step [400/403], Loss: 0.6879\n",
      "Epoch [12/30], Step [100/403], Loss: 0.6578\n",
      "Epoch [12/30], Step [200/403], Loss: 0.6823\n",
      "Epoch [12/30], Step [300/403], Loss: 0.6727\n",
      "Epoch [12/30], Step [400/403], Loss: 0.6434\n",
      "Epoch [13/30], Step [100/403], Loss: 0.6716\n",
      "Epoch [13/30], Step [200/403], Loss: 0.6656\n",
      "Epoch [13/30], Step [300/403], Loss: 0.6749\n",
      "Epoch [13/30], Step [400/403], Loss: 0.6561\n",
      "Epoch [14/30], Step [100/403], Loss: 0.6646\n",
      "Epoch [14/30], Step [200/403], Loss: 0.6500\n",
      "Epoch [14/30], Step [300/403], Loss: 0.6661\n",
      "Epoch [14/30], Step [400/403], Loss: 0.6569\n",
      "Epoch [15/30], Step [100/403], Loss: 0.6621\n",
      "Epoch [15/30], Step [200/403], Loss: 0.6870\n",
      "Epoch [15/30], Step [300/403], Loss: 0.6382\n",
      "Epoch [15/30], Step [400/403], Loss: 0.6526\n",
      "Epoch [16/30], Step [100/403], Loss: 0.6701\n",
      "Epoch [16/30], Step [200/403], Loss: 0.6594\n",
      "Epoch [16/30], Step [300/403], Loss: 0.6468\n",
      "Epoch [16/30], Step [400/403], Loss: 0.6498\n",
      "Epoch [17/30], Step [100/403], Loss: 0.6508\n",
      "Epoch [17/30], Step [200/403], Loss: 0.6794\n",
      "Epoch [17/30], Step [300/403], Loss: 0.6490\n",
      "Epoch [17/30], Step [400/403], Loss: 0.6468\n",
      "Epoch [18/30], Step [100/403], Loss: 0.6666\n",
      "Epoch [18/30], Step [200/403], Loss: 0.6523\n",
      "Epoch [18/30], Step [300/403], Loss: 0.6509\n",
      "Epoch [18/30], Step [400/403], Loss: 0.6738\n",
      "Epoch [19/30], Step [100/403], Loss: 0.6598\n",
      "Epoch [19/30], Step [200/403], Loss: 0.6416\n",
      "Epoch [19/30], Step [300/403], Loss: 0.6594\n",
      "Epoch [19/30], Step [400/403], Loss: 0.6668\n",
      "Epoch [20/30], Step [100/403], Loss: 0.6220\n",
      "Epoch [20/30], Step [200/403], Loss: 0.6841\n",
      "Epoch [20/30], Step [300/403], Loss: 0.6594\n",
      "Epoch [20/30], Step [400/403], Loss: 0.6610\n",
      "Epoch [21/30], Step [100/403], Loss: 0.6464\n",
      "Epoch [21/30], Step [200/403], Loss: 0.6783\n",
      "Epoch [21/30], Step [300/403], Loss: 0.6303\n",
      "Epoch [21/30], Step [400/403], Loss: 0.6648\n",
      "Epoch [22/30], Step [100/403], Loss: 0.6345\n",
      "Epoch [22/30], Step [200/403], Loss: 0.6497\n",
      "Epoch [22/30], Step [300/403], Loss: 0.6767\n",
      "Epoch [22/30], Step [400/403], Loss: 0.6561\n",
      "Epoch [23/30], Step [100/403], Loss: 0.6663\n",
      "Epoch [23/30], Step [200/403], Loss: 0.6512\n",
      "Epoch [23/30], Step [300/403], Loss: 0.6721\n",
      "Epoch [23/30], Step [400/403], Loss: 0.6303\n",
      "Epoch [24/30], Step [100/403], Loss: 0.6430\n",
      "Epoch [24/30], Step [200/403], Loss: 0.6490\n",
      "Epoch [24/30], Step [300/403], Loss: 0.6291\n",
      "Epoch [24/30], Step [400/403], Loss: 0.6827\n",
      "Epoch [25/30], Step [100/403], Loss: 0.6517\n",
      "Epoch [25/30], Step [200/403], Loss: 0.6563\n",
      "Epoch [25/30], Step [300/403], Loss: 0.6339\n",
      "Epoch [25/30], Step [400/403], Loss: 0.6621\n",
      "Epoch [26/30], Step [100/403], Loss: 0.6462\n",
      "Epoch [26/30], Step [200/403], Loss: 0.6742\n",
      "Epoch [26/30], Step [300/403], Loss: 0.6334\n",
      "Epoch [26/30], Step [400/403], Loss: 0.6475\n",
      "Epoch [27/30], Step [100/403], Loss: 0.6463\n",
      "Epoch [27/30], Step [200/403], Loss: 0.6492\n",
      "Epoch [27/30], Step [300/403], Loss: 0.6582\n",
      "Epoch [27/30], Step [400/403], Loss: 0.6454\n",
      "Epoch [28/30], Step [100/403], Loss: 0.6663\n",
      "Epoch [28/30], Step [200/403], Loss: 0.6633\n",
      "Epoch [28/30], Step [300/403], Loss: 0.6469\n",
      "Epoch [28/30], Step [400/403], Loss: 0.6352\n",
      "Epoch [29/30], Step [100/403], Loss: 0.6312\n",
      "Epoch [29/30], Step [200/403], Loss: 0.5955\n",
      "Epoch [29/30], Step [300/403], Loss: 0.6730\n",
      "Epoch [29/30], Step [400/403], Loss: 0.6866\n",
      "Epoch [30/30], Step [100/403], Loss: 0.6535\n",
      "Epoch [30/30], Step [200/403], Loss: 0.6697\n",
      "Epoch [30/30], Step [300/403], Loss: 0.6659\n",
      "Epoch [30/30], Step [400/403], Loss: 0.5981\n",
      "Loss: 0.6400, Accuracy: 64.29%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6400347181728908, 64.28571428571429)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration\n",
    "input_size = 56\n",
    "hidden_size = 128\n",
    "num_epochs = 30\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize the model, criterion, and optimizer\n",
    "model = Depression_Classifier_v_2(input_size, hidden_size).to(device)\n",
    "#criterion = nn.BCEWithLogitsLoss()  # Combines sigmoid and binary cross-entropy loss\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizers = ['Adam', 'SGD']\n",
    "train_model(model, train_dataloader2, criterion, optimizer, num_epochs, device)\n",
    "evaluate_model(model, test_dataloader2, criterion, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'Models/MH_PHQ_S.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
