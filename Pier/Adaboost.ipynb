{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the path to the directory where your module is located\n",
    "module_path = os.path.abspath(os.path.join('..', 'C:\\\\Users\\\\pier1\\\\OneDrive\\\\Desktop\\\\uni\\\\Master\\\\2.Semester\\\\Machine Learning (WIWI)\\\\Project\\\\Data for depression\\\\'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Now you can import your module\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('..\\data\\Threshold_10_Operator_-_Depressionfeature_MH_PHQ_S_PercentofDataset_100_v2.csv')\n",
    "print_information(df)\n",
    "\n",
    "features = []\n",
    "targets = []\n",
    "for indx, row in df.iterrows():\n",
    "    feature = []\n",
    "    for column in df.columns:\n",
    "        if 'FEATURE' in column:\n",
    "            feature.append(row[column])\n",
    "    features.append(feature)\n",
    "    targets.append(row['Depression'])\n",
    "\n",
    "features = np.array(features, dtype=np.float32)\n",
    "targets = np.array(targets, dtype=np.int16)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features,targets, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter tuning\n",
    "# results = {}\n",
    "\n",
    "# depths = [1,2,3,4]\n",
    "# n_estimators = [50,60,70,80,90,100]\n",
    "# learning_rates = [0.3,0.6,1]\n",
    "# number = 0\n",
    "# all_numbers = len(depths) * len(n_estimators) * len(learning_rates)\n",
    "# for depth in depths:\n",
    "#     for n_estimator in n_estimators:\n",
    "#         for learning_rate in learning_rates:\n",
    "#             number += 1\n",
    "#             base_estimator = DecisionTreeClassifier(max_depth=depth)\n",
    "#             ada_boost = AdaBoostClassifier(estimator=base_estimator, n_estimators=n_estimator, learning_rate=learning_rate, random_state=42)\n",
    "#             ada_boost.fit(X_train, y_train)\n",
    "#             y_pred = ada_boost.predict(X_test)\n",
    "#             accuracy = accuracy_score(y_test, y_pred)\n",
    "#             results[(depth, n_estimator, learning_rate)] = accuracy\n",
    "#             print(f'{number}/{all_numbers} - Accuracy: {accuracy} - Depth: {depth} - Estimators: {n_estimator} - Learning Rate: {learning_rate}')\n",
    "\n",
    "# print(results)\n",
    "\n",
    "# Using the optimal hyperparameters to get metrices and scores\n",
    "# learning_rate = 1 # or 0.8\n",
    "# depth = 4\n",
    "# n_estimator = 100\n",
    "\n",
    "# base_estimator = DecisionTreeClassifier(max_depth=depth)\n",
    "# ada_boost = AdaBoostClassifier(estimator=base_estimator, n_estimators=n_estimator, learning_rate=learning_rate, random_state=42)\n",
    "# ada_boost.fit(X_train, y_train)\n",
    "# y_pred = ada_boost.predict(X_test)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Generate confusion matrix\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# # Plot confusion matrix\n",
    "# plt.figure(figsize=(9, 6))\n",
    "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "# plt.xlabel('Predicted Labels')\n",
    "# plt.ylabel('True Labels')\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.show()\n",
    "\n",
    "# TN, FP, FN, TP = cm.ravel()\n",
    "# accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "# precision = TP / (TP + FP)\n",
    "# recall = TP / (TP + FN) # True positive rate\n",
    "# FNR = FN / (TP + FN) # False negative rate\n",
    "# f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# print('Accuracy: ', accuracy)\n",
    "# print('Precision: ', precision)\n",
    "# print('Recall: ', recall)\n",
    "# print('F1: ', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling 1\n",
    "- Best for BP_PHQ_9_v1 is a Depth of 4, with 100 Trees and a Learning Rate of 0.8 (Accuracy 99%)\n",
    "- Best for MH_PHQ_9_v1 is a Depth of 4, with 100 Trees and a Learning Rate of 1 (Accuracy 90%)\n",
    "### Sampling 2\n",
    "- Best for BP_PHQ_9_v2 is a Depth of 4, with 90 Trees and a Learning Rate of 0.3 (Accuracy 97%)\n",
    "- Best for MH_PHQ_9_v2 is a Depth of 4, with 100 Trees and a Learning Rate of 1 (Accuracy 89%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "depth_df = []\n",
    "n_estimators_df = []\n",
    "learning_rate_df = []\n",
    "accuracy_df = []\n",
    "\n",
    "for key,value in results.items():\n",
    "    accuracy_df.append(value)\n",
    "    depth_df.append(key[0])\n",
    "    n_estimators_df.append(key[1])\n",
    "    learning_rate_df.append(key[2])\n",
    " \n",
    "df['depth'] = depth_df\n",
    "df['Number_Trees'] = n_estimators_df\n",
    "df['Learning Rate'] = learning_rate_df\n",
    "df['Accuracy'] = accuracy_df\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Adaboost_MH_PHQ_S_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
