{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the path to the directory where your module is located\n",
    "module_path = os.path.abspath(os.path.join('..', 'C:\\\\Users\\\\pier1\\\\OneDrive\\\\Desktop\\\\uni\\\\Master\\\\2.Semester\\\\Machine Learning (WIWI)\\\\Project\\\\Data for depression\\\\'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Now you can import your module\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from NN import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "ID_1          1076\n",
      "ID_2          1076\n",
      "group_id      1076\n",
      "SEX           1076\n",
      "AGE           1076\n",
      "              ... \n",
      "FEATURE_51    1076\n",
      "FEATURE_52    1076\n",
      "FEATURE_53    1076\n",
      "FEATURE_54    1076\n",
      "FEATURE_55    1076\n",
      "Length: 65, dtype: int64\n",
      "1.0\n",
      "ID_1          1076\n",
      "ID_2          1076\n",
      "group_id      1076\n",
      "SEX           1076\n",
      "AGE           1076\n",
      "              ... \n",
      "FEATURE_51    1076\n",
      "FEATURE_52    1076\n",
      "FEATURE_53    1076\n",
      "FEATURE_54    1076\n",
      "FEATURE_55    1076\n",
      "Length: 65, dtype: int64\n",
      "2.0\n",
      "ID_1          1076\n",
      "ID_2          1076\n",
      "group_id      1076\n",
      "SEX           1076\n",
      "AGE           1076\n",
      "              ... \n",
      "FEATURE_51    1076\n",
      "FEATURE_52    1076\n",
      "FEATURE_53    1076\n",
      "FEATURE_54    1076\n",
      "FEATURE_55    1076\n",
      "Length: 65, dtype: int64\n",
      "3.0\n",
      "ID_1          1076\n",
      "ID_2          1076\n",
      "group_id      1076\n",
      "SEX           1076\n",
      "AGE           1076\n",
      "              ... \n",
      "FEATURE_51    1076\n",
      "FEATURE_52    1076\n",
      "FEATURE_53    1076\n",
      "FEATURE_54    1076\n",
      "FEATURE_55    1076\n",
      "Length: 65, dtype: int64\n",
      "6.0\n",
      "ID_1          1076\n",
      "ID_2          1076\n",
      "group_id      1076\n",
      "SEX           1076\n",
      "AGE           1076\n",
      "              ... \n",
      "FEATURE_51    1076\n",
      "FEATURE_52    1076\n",
      "FEATURE_53    1076\n",
      "FEATURE_54    1076\n",
      "FEATURE_55    1076\n",
      "Length: 65, dtype: int64\n",
      "8.0\n",
      "ID_1          1076\n",
      "ID_2          1076\n",
      "group_id      1076\n",
      "SEX           1076\n",
      "AGE           1076\n",
      "              ... \n",
      "FEATURE_51    1076\n",
      "FEATURE_52    1076\n",
      "FEATURE_53    1076\n",
      "FEATURE_54    1076\n",
      "FEATURE_55    1076\n",
      "Length: 65, dtype: int64\n",
      "9.0\n",
      "ID_1          1076\n",
      "ID_2          1076\n",
      "group_id      1076\n",
      "SEX           1076\n",
      "AGE           1076\n",
      "              ... \n",
      "FEATURE_51    1076\n",
      "FEATURE_52    1076\n",
      "FEATURE_53    1076\n",
      "FEATURE_54    1076\n",
      "FEATURE_55    1076\n",
      "Length: 65, dtype: int64\n",
      "---Number of Non-Depression and Depression---\n",
      "3228 4304\n",
      "torch.Size([6778, 56]) torch.Size([6778]) torch.Size([754, 56]) torch.Size([754])\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('..\\data\\Threshold_3_Operator_-_Depressionfeature_BP_PHQ_9_PercentofDataset_100_v2.csv')\n",
    "print_information(df)\n",
    "# 0.9 train, 0.1 test\n",
    "train_df, test_df = train_test_split(df, test_size=0.1, random_state=42)\n",
    "# 0.8 train, 0.2 validation\n",
    "#train_df, validation_df = train_test_split(train_df, train_size=0.8, random_state=42)\n",
    "\n",
    "train_features, train_targets = df_to_tensor(train_df,features_column='FEATURES', target_col='Depression')\n",
    "#validation_features, validation_targets = df_to_tensor(validation_df, features_column='FEATURES', target_col='Depression')\n",
    "test_features, test_targets = df_to_tensor(test_df, features_column='FEATURES', target_col='Depression')\n",
    "\n",
    "#print(train_features.shape, train_targets.shape, validation_features.shape, validation_targets.shape, test_features.shape, test_targets.shape)\n",
    "print(train_features.shape, train_targets.shape, test_features.shape, test_targets.shape)\n",
    "\n",
    "train_dataset = CustomDataset(train_features, train_targets)\n",
    "#validation_dataset = CustomDataset(validation_features, validation_targets)\n",
    "test_dataset = CustomDataset(test_features, test_targets)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "#validation_dataloader = DataLoader(validation_dataset, batch_size=32, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/60], Step [100/212], Loss: 0.6636\n",
      "Epoch [1/60], Step [200/212], Loss: 0.5826\n",
      "Epoch [2/60], Step [100/212], Loss: 0.5623\n",
      "Epoch [2/60], Step [200/212], Loss: 0.5240\n",
      "Epoch [3/60], Step [100/212], Loss: 0.5047\n",
      "Epoch [3/60], Step [200/212], Loss: 0.5090\n",
      "Epoch [4/60], Step [100/212], Loss: 0.4937\n",
      "Epoch [4/60], Step [200/212], Loss: 0.4702\n",
      "Epoch [5/60], Step [100/212], Loss: 0.4727\n",
      "Epoch [5/60], Step [200/212], Loss: 0.4525\n",
      "Epoch [6/60], Step [100/212], Loss: 0.4488\n",
      "Epoch [6/60], Step [200/212], Loss: 0.4484\n",
      "Epoch [7/60], Step [100/212], Loss: 0.4448\n",
      "Epoch [7/60], Step [200/212], Loss: 0.4273\n",
      "Epoch [8/60], Step [100/212], Loss: 0.4285\n",
      "Epoch [8/60], Step [200/212], Loss: 0.4137\n",
      "Epoch [9/60], Step [100/212], Loss: 0.4000\n",
      "Epoch [9/60], Step [200/212], Loss: 0.3953\n",
      "Epoch [10/60], Step [100/212], Loss: 0.3955\n",
      "Epoch [10/60], Step [200/212], Loss: 0.3965\n",
      "Epoch [11/60], Step [100/212], Loss: 0.3823\n",
      "Epoch [11/60], Step [200/212], Loss: 0.3809\n",
      "Epoch [12/60], Step [100/212], Loss: 0.3737\n",
      "Epoch [12/60], Step [200/212], Loss: 0.3662\n",
      "Epoch [13/60], Step [100/212], Loss: 0.3588\n",
      "Epoch [13/60], Step [200/212], Loss: 0.3615\n",
      "Epoch [14/60], Step [100/212], Loss: 0.3494\n",
      "Epoch [14/60], Step [200/212], Loss: 0.3560\n",
      "Epoch [15/60], Step [100/212], Loss: 0.3498\n",
      "Epoch [15/60], Step [200/212], Loss: 0.3399\n",
      "Epoch [16/60], Step [100/212], Loss: 0.3322\n",
      "Epoch [16/60], Step [200/212], Loss: 0.3370\n",
      "Epoch [17/60], Step [100/212], Loss: 0.3358\n",
      "Epoch [17/60], Step [200/212], Loss: 0.3334\n",
      "Epoch [18/60], Step [100/212], Loss: 0.3048\n",
      "Epoch [18/60], Step [200/212], Loss: 0.3435\n",
      "Epoch [19/60], Step [100/212], Loss: 0.3336\n",
      "Epoch [19/60], Step [200/212], Loss: 0.3213\n",
      "Epoch [20/60], Step [100/212], Loss: 0.3139\n",
      "Epoch [20/60], Step [200/212], Loss: 0.3173\n",
      "Epoch [21/60], Step [100/212], Loss: 0.3023\n",
      "Epoch [21/60], Step [200/212], Loss: 0.3035\n",
      "Epoch [22/60], Step [100/212], Loss: 0.2948\n",
      "Epoch [22/60], Step [200/212], Loss: 0.2962\n",
      "Epoch [23/60], Step [100/212], Loss: 0.3113\n",
      "Epoch [23/60], Step [200/212], Loss: 0.2915\n",
      "Epoch [24/60], Step [100/212], Loss: 0.2721\n",
      "Epoch [24/60], Step [200/212], Loss: 0.2923\n",
      "Epoch [25/60], Step [100/212], Loss: 0.2690\n",
      "Epoch [25/60], Step [200/212], Loss: 0.2955\n",
      "Epoch [26/60], Step [100/212], Loss: 0.2855\n",
      "Epoch [26/60], Step [200/212], Loss: 0.2857\n",
      "Epoch [27/60], Step [100/212], Loss: 0.2700\n",
      "Epoch [27/60], Step [200/212], Loss: 0.2870\n",
      "Epoch [28/60], Step [100/212], Loss: 0.2740\n",
      "Epoch [28/60], Step [200/212], Loss: 0.2796\n",
      "Epoch [29/60], Step [100/212], Loss: 0.2624\n",
      "Epoch [29/60], Step [200/212], Loss: 0.2584\n",
      "Epoch [30/60], Step [100/212], Loss: 0.2546\n",
      "Epoch [30/60], Step [200/212], Loss: 0.2608\n",
      "Epoch [31/60], Step [100/212], Loss: 0.2503\n",
      "Epoch [31/60], Step [200/212], Loss: 0.2473\n",
      "Epoch [32/60], Step [100/212], Loss: 0.2367\n",
      "Epoch [32/60], Step [200/212], Loss: 0.2423\n",
      "Epoch [33/60], Step [100/212], Loss: 0.2451\n",
      "Epoch [33/60], Step [200/212], Loss: 0.2396\n",
      "Epoch [34/60], Step [100/212], Loss: 0.2365\n",
      "Epoch [34/60], Step [200/212], Loss: 0.2421\n",
      "Epoch [35/60], Step [100/212], Loss: 0.2284\n",
      "Epoch [35/60], Step [200/212], Loss: 0.2298\n",
      "Epoch [36/60], Step [100/212], Loss: 0.2382\n",
      "Epoch [36/60], Step [200/212], Loss: 0.2204\n",
      "Epoch [37/60], Step [100/212], Loss: 0.2043\n",
      "Epoch [37/60], Step [200/212], Loss: 0.2304\n",
      "Epoch [38/60], Step [100/212], Loss: 0.2192\n",
      "Epoch [38/60], Step [200/212], Loss: 0.2360\n",
      "Epoch [39/60], Step [100/212], Loss: 0.2214\n",
      "Epoch [39/60], Step [200/212], Loss: 0.2157\n",
      "Epoch [40/60], Step [100/212], Loss: 0.2080\n",
      "Epoch [40/60], Step [200/212], Loss: 0.2070\n",
      "Epoch [41/60], Step [100/212], Loss: 0.2128\n",
      "Epoch [41/60], Step [200/212], Loss: 0.1940\n",
      "Epoch [42/60], Step [100/212], Loss: 0.1919\n",
      "Epoch [42/60], Step [200/212], Loss: 0.2001\n",
      "Epoch [43/60], Step [100/212], Loss: 0.2019\n",
      "Epoch [43/60], Step [200/212], Loss: 0.1946\n",
      "Epoch [44/60], Step [100/212], Loss: 0.1828\n",
      "Epoch [44/60], Step [200/212], Loss: 0.1925\n",
      "Epoch [45/60], Step [100/212], Loss: 0.1894\n",
      "Epoch [45/60], Step [200/212], Loss: 0.1784\n",
      "Epoch [46/60], Step [100/212], Loss: 0.1886\n",
      "Epoch [46/60], Step [200/212], Loss: 0.1818\n",
      "Epoch [47/60], Step [100/212], Loss: 0.1591\n",
      "Epoch [47/60], Step [200/212], Loss: 0.1904\n",
      "Epoch [48/60], Step [100/212], Loss: 0.1945\n",
      "Epoch [48/60], Step [200/212], Loss: 0.1776\n",
      "Epoch [49/60], Step [100/212], Loss: 0.1630\n",
      "Epoch [49/60], Step [200/212], Loss: 0.1803\n",
      "Epoch [50/60], Step [100/212], Loss: 0.1597\n",
      "Epoch [50/60], Step [200/212], Loss: 0.1735\n",
      "Epoch [51/60], Step [100/212], Loss: 0.1660\n",
      "Epoch [51/60], Step [200/212], Loss: 0.1815\n",
      "Epoch [52/60], Step [100/212], Loss: 0.1488\n",
      "Epoch [52/60], Step [200/212], Loss: 0.1675\n",
      "Epoch [53/60], Step [100/212], Loss: 0.1730\n",
      "Epoch [53/60], Step [200/212], Loss: 0.1716\n",
      "Epoch [54/60], Step [100/212], Loss: 0.1623\n",
      "Epoch [54/60], Step [200/212], Loss: 0.1484\n",
      "Epoch [55/60], Step [100/212], Loss: 0.1438\n",
      "Epoch [55/60], Step [200/212], Loss: 0.1619\n",
      "Epoch [56/60], Step [100/212], Loss: 0.1429\n",
      "Epoch [56/60], Step [200/212], Loss: 0.1470\n",
      "Epoch [57/60], Step [100/212], Loss: 0.1332\n",
      "Epoch [57/60], Step [200/212], Loss: 0.1601\n",
      "Epoch [58/60], Step [100/212], Loss: 0.1604\n",
      "Epoch [58/60], Step [200/212], Loss: 0.1740\n",
      "Epoch [59/60], Step [100/212], Loss: 0.1778\n",
      "Epoch [59/60], Step [200/212], Loss: 0.1536\n",
      "Epoch [60/60], Step [100/212], Loss: 0.1405\n",
      "Epoch [60/60], Step [200/212], Loss: 0.1431\n",
      "Loss: 0.2440, Accuracy: 89.92%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.24401644244790077, 89.92042440318302)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration\n",
    "input_size = 56\n",
    "hidden_size = 128\n",
    "num_epochs = 60\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Model is bad at 94 % accuracy, because 94 percent of the data is not depressed (PHQ_9)\n",
    "# Initialize the model, criterion, and optimizer\n",
    "model = Depression_Classifier_v_1(input_size, hidden_size).to(device)\n",
    "#criterion = nn.BCEWithLogitsLoss()  # Combines sigmoid and binary cross-entropy loss\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizers = ['Adam', 'SGD']\n",
    "train_model(model, train_dataloader, criterion, optimizer, num_epochs, device)\n",
    "evaluate_model(model, test_dataloader, criterion, device)\n",
    "\n",
    "# results = {}\n",
    "# results = cross_validation(train_dataloader, validation_dataloader, test_dataloader, criterion, num_epochs, device)\n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "models_df = []\n",
    "optimizer_df = []\n",
    "learning_rate_df = []\n",
    "momentum_df = []\n",
    "accuracy_df = []\n",
    "validation_loss_df = []\n",
    "for key,value in results.items():\n",
    "    accuracy_df.append(value['accuracy'])\n",
    "    validation_loss_df.append(value['validation_loss'])\n",
    "    opti = key[1]\n",
    "    models_df.append(key[0])\n",
    "    optimizer_df.append(opti)\n",
    "    learning_rate_df.append(key[2])\n",
    "    if opti == 'SGD':\n",
    "        momentum_df.append(key[3])\n",
    "    else:\n",
    "        momentum_df.append(None)\n",
    "        \n",
    "df['Model'] = models_df\n",
    "df['Optimizer'] = optimizer_df\n",
    "df['Learning Rate'] = learning_rate_df\n",
    "df['Momentum'] = momentum_df\n",
    "df['Validation Loss'] = validation_loss_df\n",
    "df['Accuracy'] = accuracy_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ID_1        ID_2                       group_id     SEX      AGE  \\\n",
      "0     R654244201  B660346201    Male_[59-65]_Healthy Weight    Male  [59-65]   \n",
      "1     A213746816  A216782516    Male_[49-53]_Healthy Weight    Male  [49-53]   \n",
      "2     H235785914  F244697514  Female_[19-23]_Healthy Weight  Female  [19-23]   \n",
      "3     B246777415  H678215302  Female_[34-38]_Healthy Weight  Female  [34-38]   \n",
      "4     H205777413  P243794416  Female_[29-33]_Healthy Weight  Female  [29-33]   \n",
      "...          ...         ...                            ...     ...      ...   \n",
      "7527  E241811415  B242796116  Female_[54-58]_Healthy Weight  Female  [54-58]   \n",
      "7528  E241811415  R651359802  Female_[54-58]_Healthy Weight  Female  [54-58]   \n",
      "7529  H678252702  E241811415  Female_[54-58]_Healthy Weight  Female  [54-58]   \n",
      "7530  E241811415  H242716215  Female_[54-58]_Healthy Weight  Female  [54-58]   \n",
      "7531  A214765516  E241811415  Female_[54-58]_Healthy Weight  Female  [54-58]   \n",
      "\n",
      "              HE_BMI           ID_COMBINED  d_PHQ  Depression  FEATURE_0  ...  \\\n",
      "0     Healthy Weight  R654244201B660346201    0.0           0   4.587974  ...   \n",
      "1     Healthy Weight  A213746816A216782516    0.0           0   4.928378  ...   \n",
      "2     Healthy Weight  H235785914F244697514    0.0           0   0.061710  ...   \n",
      "3     Healthy Weight  B246777415H678215302    0.0           0   4.198437  ...   \n",
      "4     Healthy Weight  H205777413P243794416    0.0           0   5.805119  ...   \n",
      "...              ...                   ...    ...         ...        ...  ...   \n",
      "7527  Healthy Weight  E241811415B242796116    9.0           1   3.883771  ...   \n",
      "7528  Healthy Weight  E241811415R651359802    9.0           1   5.281421  ...   \n",
      "7529  Healthy Weight  H678252702E241811415    9.0           1   3.922244  ...   \n",
      "7530  Healthy Weight  E241811415H242716215    9.0           1   4.807029  ...   \n",
      "7531  Healthy Weight  A214765516E241811415    9.0           1   5.543419  ...   \n",
      "\n",
      "      FEATURE_46  FEATURE_47  FEATURE_48  FEATURE_49  FEATURE_50  FEATURE_51  \\\n",
      "0      -0.470662   -0.470667    1.337908   -0.470667   -0.470663   -0.470667   \n",
      "1      -0.434740   -0.434746    1.746882   -0.434746   -0.434742   -0.434746   \n",
      "2      -0.364082   -0.364087    0.444544   -0.364088   -0.364084   -0.364087   \n",
      "3      -0.431215   -0.431224    2.769242   -0.431224   -0.431217   -0.431224   \n",
      "4      -0.359374   -0.359379    2.203302   -0.359379   -0.359375   -0.359379   \n",
      "...          ...         ...         ...         ...         ...         ...   \n",
      "7527   -0.419551   -0.419558    2.696056   -0.419558   -0.419553   -0.419558   \n",
      "7528   -0.416734   -0.416741    1.943729   -0.416741   -0.416736   -0.416741   \n",
      "7529   -0.429544   -0.429555    2.776063   -0.429556   -0.429547   -0.429555   \n",
      "7530   -0.426889   -0.426894    1.584139   -0.426895   -0.426891   -0.426894   \n",
      "7531   -0.402869   -0.402873    1.256301   -0.402873   -0.402870   -0.402873   \n",
      "\n",
      "      FEATURE_52  FEATURE_53  FEATURE_54  FEATURE_55  \n",
      "0       1.276942   -0.470667   -0.470664   -0.470667  \n",
      "1       1.947586   -0.434746   -0.434743   -0.434746  \n",
      "2       0.445223   -0.364088   -0.364085   -0.364087  \n",
      "3       2.675090   -0.431224   -0.431219   -0.431224  \n",
      "4       2.936452   -0.359379   -0.359376   -0.359379  \n",
      "...          ...         ...         ...         ...  \n",
      "7527    3.091331   -0.419558   -0.419555   -0.419558  \n",
      "7528    2.247871   -0.416741   -0.416737   -0.416741  \n",
      "7529    2.822072   -0.429556   -0.429550   -0.429555  \n",
      "7530    1.713844   -0.426895   -0.426892   -0.426894  \n",
      "7531    1.441114   -0.402873   -0.402871   -0.402873  \n",
      "\n",
      "[7532 rows x 65 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)\n",
    "torch.save(model.state_dict(), 'models/BP_PHQ_9_v2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Results/FNN_BP_PHQ_9_minus_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the csv data to compare the different models and cross-validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_phq_9 = pd.read_csv('Results/FNN_BP_PHQ_9_minus_v2.csv')\n",
    "mh_phq_s = pd.read_csv('Results/FNN_MH_PHQ_S_minus_v2.csv')\n",
    "\n",
    "max_index_phq9 = bp_phq_9['Accuracy'].idxmax()\n",
    "max_index_mh_phq_s = mh_phq_s['Accuracy'].idxmax()\n",
    "\n",
    "print(bp_phq_9.loc[max_index_phq9])\n",
    "print(mh_phq_s.loc[max_index_mh_phq_s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Based on the cross-validation with different learning rates, momentum values, optimizers, models and 30 epochs the best accuracy is based of\n",
    "- Model_2, Adam, lr = 0.001 with a accuracy of 94% with the depression_classifier PHQ_9 and sample_1\n",
    "- Model_2, Adam, lr = 0.001 with a accuracy of 83% with the depression_classifier MH_PHQ_s and sample_1\n",
    "- Model_1, Adam, lr = 0.001 with a accuracy of 84% with the depression_classifier PHQ_9 and sample_2\n",
    "- Model_2, Adam, lr = 0.001 with a accuracy of 81% with the depression_classifier MH_PHQ_s and sample_2\n",
    "- Using these values we run for 60 epochs\n",
    "- Model_2, Adam, lr = 0.001 with a accuracy of 95% with the depression_classifier PHQ_9 sample_1\n",
    "- Model_2, Adam, lr = 0.001 with a accuracy of 89% with the depression_classifier MH_PHQ_s sample_1\n",
    "- Model_1, Adam, lr = 0.001 with a accuracy of 89% with the depression_classifier PHQ_9 and sample_2\n",
    "- Model_2, Adam, lr = 0.001 with a accuracy of 88% with the depression_classifier MH_PHQ_s and sample_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
