{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the path to the directory where your module is located\n",
    "module_path = os.path.abspath(os.path.join('..', 'C:\\\\Users\\\\pier1\\\\OneDrive\\\\Desktop\\\\uni\\\\Master\\\\2.Semester\\\\Machine Learning (WIWI)\\\\Project\\\\Data for depression\\\\'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Now you can import your module\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from NN import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9.0\n",
      "ID_1          203\n",
      "ID_2          203\n",
      "group_id      203\n",
      "SEX           203\n",
      "AGE           203\n",
      "             ... \n",
      "FEATURE_51    203\n",
      "FEATURE_52    203\n",
      "FEATURE_53    203\n",
      "FEATURE_54    203\n",
      "FEATURE_55    203\n",
      "Length: 65, dtype: int64\n",
      "-8.0\n",
      "ID_1          149\n",
      "ID_2          149\n",
      "group_id      149\n",
      "SEX           149\n",
      "AGE           149\n",
      "             ... \n",
      "FEATURE_51    149\n",
      "FEATURE_52    149\n",
      "FEATURE_53    149\n",
      "FEATURE_54    149\n",
      "FEATURE_55    149\n",
      "Length: 65, dtype: int64\n",
      "-6.0\n",
      "ID_1          146\n",
      "ID_2          146\n",
      "group_id      146\n",
      "SEX           146\n",
      "AGE           146\n",
      "             ... \n",
      "FEATURE_51    146\n",
      "FEATURE_52    146\n",
      "FEATURE_53    146\n",
      "FEATURE_54    146\n",
      "FEATURE_55    146\n",
      "Length: 65, dtype: int64\n",
      "-3.0\n",
      "ID_1          403\n",
      "ID_2          403\n",
      "group_id      403\n",
      "SEX           403\n",
      "AGE           403\n",
      "             ... \n",
      "FEATURE_51    403\n",
      "FEATURE_52    403\n",
      "FEATURE_53    403\n",
      "FEATURE_54    403\n",
      "FEATURE_55    403\n",
      "Length: 65, dtype: int64\n",
      "-2.0\n",
      "ID_1          460\n",
      "ID_2          460\n",
      "group_id      460\n",
      "SEX           460\n",
      "AGE           460\n",
      "             ... \n",
      "FEATURE_51    460\n",
      "FEATURE_52    460\n",
      "FEATURE_53    460\n",
      "FEATURE_54    460\n",
      "FEATURE_55    460\n",
      "Length: 65, dtype: int64\n",
      "-1.0\n",
      "ID_1          3318\n",
      "ID_2          3318\n",
      "group_id      3318\n",
      "SEX           3318\n",
      "AGE           3318\n",
      "              ... \n",
      "FEATURE_51    3318\n",
      "FEATURE_52    3318\n",
      "FEATURE_53    3318\n",
      "FEATURE_54    3318\n",
      "FEATURE_55    3318\n",
      "Length: 65, dtype: int64\n",
      "0.0\n",
      "ID_1          5790\n",
      "ID_2          5790\n",
      "group_id      5790\n",
      "SEX           5790\n",
      "AGE           5790\n",
      "              ... \n",
      "FEATURE_51    5790\n",
      "FEATURE_52    5790\n",
      "FEATURE_53    5790\n",
      "FEATURE_54    5790\n",
      "FEATURE_55    5790\n",
      "Length: 65, dtype: int64\n",
      "1.0\n",
      "ID_1          3318\n",
      "ID_2          3318\n",
      "group_id      3318\n",
      "SEX           3318\n",
      "AGE           3318\n",
      "              ... \n",
      "FEATURE_51    3318\n",
      "FEATURE_52    3318\n",
      "FEATURE_53    3318\n",
      "FEATURE_54    3318\n",
      "FEATURE_55    3318\n",
      "Length: 65, dtype: int64\n",
      "2.0\n",
      "ID_1          460\n",
      "ID_2          460\n",
      "group_id      460\n",
      "SEX           460\n",
      "AGE           460\n",
      "             ... \n",
      "FEATURE_51    460\n",
      "FEATURE_52    460\n",
      "FEATURE_53    460\n",
      "FEATURE_54    460\n",
      "FEATURE_55    460\n",
      "Length: 65, dtype: int64\n",
      "3.0\n",
      "ID_1          403\n",
      "ID_2          403\n",
      "group_id      403\n",
      "SEX           403\n",
      "AGE           403\n",
      "             ... \n",
      "FEATURE_51    403\n",
      "FEATURE_52    403\n",
      "FEATURE_53    403\n",
      "FEATURE_54    403\n",
      "FEATURE_55    403\n",
      "Length: 65, dtype: int64\n",
      "6.0\n",
      "ID_1          146\n",
      "ID_2          146\n",
      "group_id      146\n",
      "SEX           146\n",
      "AGE           146\n",
      "             ... \n",
      "FEATURE_51    146\n",
      "FEATURE_52    146\n",
      "FEATURE_53    146\n",
      "FEATURE_54    146\n",
      "FEATURE_55    146\n",
      "Length: 65, dtype: int64\n",
      "8.0\n",
      "ID_1          149\n",
      "ID_2          149\n",
      "group_id      149\n",
      "SEX           149\n",
      "AGE           149\n",
      "             ... \n",
      "FEATURE_51    149\n",
      "FEATURE_52    149\n",
      "FEATURE_53    149\n",
      "FEATURE_54    149\n",
      "FEATURE_55    149\n",
      "Length: 65, dtype: int64\n",
      "9.0\n",
      "ID_1          203\n",
      "ID_2          203\n",
      "group_id      203\n",
      "SEX           203\n",
      "AGE           203\n",
      "             ... \n",
      "FEATURE_51    203\n",
      "FEATURE_52    203\n",
      "FEATURE_53    203\n",
      "FEATURE_54    203\n",
      "FEATURE_55    203\n",
      "Length: 65, dtype: int64\n",
      "---Number of Non-Depression and Depression---\n",
      "13346 1802\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m train_df, test_df \u001b[38;5;241m=\u001b[39m train_test_split(df, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 0.8 train, 0.2 validation\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#train_df, validation_df = train_test_split(train_df, train_size=0.8, random_state=42)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m train_features, train_targets \u001b[38;5;241m=\u001b[39m \u001b[43mdf_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfeatures_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFEATURES\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDepression\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#validation_features, validation_targets = df_to_tensor(validation_df, features_column='FEATURES', target_col='Depression')\u001b[39;00m\n\u001b[0;32m     10\u001b[0m test_features, test_targets \u001b[38;5;241m=\u001b[39m df_to_tensor(test_df, features_column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFEATURES\u001b[39m\u001b[38;5;124m'\u001b[39m, target_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDepression\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pier1\\OneDrive\\Desktop\\uni\\Master\\2.Semester\\Machine Learning (WIWI)\\Project\\Data for depression\\Pier\\NN.py:36\u001b[0m, in \u001b[0;36mdf_to_tensor\u001b[1;34m(df, features_column, target_col)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFEATURE\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m column:\n\u001b[1;32m---> 36\u001b[0m         feature\u001b[38;5;241m.\u001b[39mappend(\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     37\u001b[0m features\u001b[38;5;241m.\u001b[39mappend(feature)\n\u001b[0;32m     38\u001b[0m targets\u001b[38;5;241m.\u001b[39mappend(row[target_col])\n",
      "File \u001b[1;32mc:\\Users\\pier1\\anaconda3\\envs\\ML\\lib\\site-packages\\pandas\\core\\series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1004\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1012\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pier1\\anaconda3\\envs\\ML\\lib\\site-packages\\pandas\\core\\series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1116\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\pier1\\anaconda3\\envs\\ML\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3651\u001b[0m casted_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_indexer(key)\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('..\\data\\Threshold_3_Operator_-_Depressionfeature_BP_PHQ_9_PercentofDataset_100.csv')\n",
    "print_information(df)\n",
    "# 0.9 train, 0.1 test\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "# 0.8 train, 0.2 validation\n",
    "#train_df, validation_df = train_test_split(train_df, train_size=0.8, random_state=42)\n",
    "\n",
    "train_features, train_targets = df_to_tensor(train_df,features_column='FEATURES', target_col='Depression')\n",
    "#validation_features, validation_targets = df_to_tensor(validation_df, features_column='FEATURES', target_col='Depression')\n",
    "test_features, test_targets = df_to_tensor(test_df, features_column='FEATURES', target_col='Depression')\n",
    "\n",
    "#print(train_features.shape, train_targets.shape, validation_features.shape, validation_targets.shape, test_features.shape, test_targets.shape)\n",
    "print(train_features.shape, train_targets.shape, test_features.shape, test_targets.shape)\n",
    "\n",
    "train_dataset = CustomDataset(train_features, train_targets)\n",
    "#validation_dataset = CustomDataset(validation_features, validation_targets)\n",
    "test_dataset = CustomDataset(test_features, test_targets)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "#validation_dataloader = DataLoader(validation_dataset, batch_size=32, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "input_size = 56\n",
    "hidden_size = 128\n",
    "num_epochs = 60\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Model is bad at 94 % accuracy, because 94 percent of the data is not depressed (PHQ_9)\n",
    "# Initialize the model, criterion, and optimizer\n",
    "model = Depression_Classifier_v_2(input_size, hidden_size).to(device)\n",
    "#criterion = nn.BCEWithLogitsLoss()  # Combines sigmoid and binary cross-entropy loss\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizers = ['Adam', 'SGD']\n",
    "train_model(model, train_dataloader, criterion, optimizer, num_epochs, device)\n",
    "evaluate_model(model, test_dataloader, criterion, device)\n",
    "\n",
    "#results = {}\n",
    "#results = cross_validation(train_dataloader, validation_dataloader, input_size, hidden_size, criterion, optimizers, device, results)\n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "models_df = []\n",
    "optimizer_df = []\n",
    "learning_rate_df = []\n",
    "momentum_df = []\n",
    "accuracy_df = []\n",
    "validation_loss_df = []\n",
    "for key,value in results.items():\n",
    "    accuracy_df.append(value['accuracy'])\n",
    "    validation_loss_df.append(value['validation_loss'])\n",
    "    opti = key[1]\n",
    "    models_df.append(key[0])\n",
    "    optimizer_df.append(opti)\n",
    "    learning_rate_df.append(key[2])\n",
    "    if opti == 'SGD':\n",
    "        momentum_df.append(key[3])\n",
    "    else:\n",
    "        momentum_df.append(None)\n",
    "        \n",
    "df['Model'] = models_df\n",
    "df['Optimizer'] = optimizer_df\n",
    "df['Learning Rate'] = learning_rate_df\n",
    "df['Momentum'] = momentum_df\n",
    "df['Validation Loss'] = validation_loss_df\n",
    "df['Accuracy'] = accuracy_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('FNN_MH_PHQ_S_minus.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the csv data to compare the different models and cross-validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_phq_9 = pd.read_csv('FNN_BP_PHQ_9_minus.csv')\n",
    "mh_phq_s = pd.read_csv('FNN_MH_PHQ_S_minus.csv')\n",
    "\n",
    "max_index_phq9 = bp_phq_9['Accuracy'].idxmax()\n",
    "max_index_mh_phq_s = mh_phq_s['Accuracy'].idxmax()\n",
    "\n",
    "print(bp_phq_9.loc[max_index_phq9])\n",
    "print(mh_phq_s.loc[max_index_mh_phq_s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Based on the cross-validation with different learning rates, momentum values, optimizers, models and 30 epochs the best accuracy is based of\n",
    "- Model_2, Adam, lr = 0.001 with a accuracy of 94% with the depression_classifier PHQ_9\n",
    "- Model_2, Adam, lr = 0.001 with a accuracy of 83% with the depression_classifier MH_PHQ_s\n",
    "- Using these values we run for 60 epochs\n",
    "- Model_2, Adam, lr = 0.001 with a accuracy of 89% with the depression_classifier MH_PHQ_s\n",
    "- Model_2, Adam, lr = 0.001 with a accuracy of 95% with the depression_classifier PHQ_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'BP_PHQ_9.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
