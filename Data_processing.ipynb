{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349bb8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from helpers import *\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "logging.basicConfig(level = logging.INFO, filename='log.log', filemode='w', format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a38a857",
   "metadata": {},
   "outputs": [],
   "source": [
    "pam16_df=pd.read_sas(\"PAM/hn16_pam.sas7bdat\")\n",
    "all16_df=pd.read_sas(\"ALL/hn16_all.sas7bdat\")\n",
    "pam14_df=pd.read_sas(\"PAM/hn14_pam.sas7bdat\")\n",
    "all14_df=pd.read_sas(\"ALL/hn14_all.sas7bdat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e20814a",
   "metadata": {},
   "source": [
    "This can be used for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f6c2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all16_df = all16_df[[\"ID\", \"year\", \"sex\", \"age\", \"BP_PHQ_9\",\n",
    "                  \"mh_PHQ_S\", \"HE_BMI\", \"mh_stress\", \"EQ5D\"]]\n",
    "all14_df = all14_df[[\"id\", \"year\", \"sex\", \"age\", \"BP_PHQ_9\",\n",
    "                  \"mh_PHQ_S\", \"HE_BMI\", \"mh_stress\", \"EQ5D\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de31364",
   "metadata": {},
   "source": [
    "process_data converts all nan Values into the mean values except the Sex Column that is processed in a different way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30915031",
   "metadata": {},
   "outputs": [],
   "source": [
    "all14_df, all16_df = process_data(all14_df), process_data(all16_df)\n",
    "all14_df.shape, all16_df.shape, pam14_df.shape, pam16_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc5a421",
   "metadata": {},
   "source": [
    "turning features into meaningful values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805df666",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all14_df['BP_PHQ_9'], all16_df['BP_PHQ_9'] = all14_df['BP_PHQ_9'].apply(Depression_Severity_), all16_df['BP_PHQ_9'].apply(Depression_Severity_)\n",
    "#all14_df['mh_PHQ_S'], all16_df['mh_PHQ_S'] = all14_df['mh_PHQ_S'].apply(Depression_Severity), all16_df['mh_PHQ_S'].apply(Depression_Severity)\n",
    "all14_df['HE_BMI'], all16_df['HE_BMI'] = all14_df['HE_BMI'].apply(BMI_range), all16_df['HE_BMI'].apply(BMI_range)\n",
    "pam14_df['sex'], pam16_df['sex'], all14_df['sex'], all16_df['sex'] = pam14_df['sex'].apply(Sex_name), pam16_df['sex'].apply(Sex_name), all14_df['sex'].apply(Sex_name), all16_df['sex'].apply(Sex_name)\n",
    "pam14_df['age'], pam16_df['age'], all14_df['age'], all16_df['age'] = pam14_df['age'].apply(Age_range), pam16_df['age'].apply(Age_range), all14_df['age'].apply(Age_range), all16_df['age'].apply(Age_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a1f33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all14_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bdac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all16_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272b28a6",
   "metadata": {},
   "source": [
    "Turn all columns to uppercase and concatenate the two dataframes from 2014 and 2016 together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f2eb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = lambda df: df.rename(columns=str.upper)\n",
    "pam14_df, pam16_df, all14_df, all16_df = map(func, [pam14_df, pam16_df, all14_df, all16_df])\n",
    "pam_combined = pd.concat([pam14_df, pam16_df], ignore_index=True)\n",
    "all_combined = pd.concat([all14_df, all16_df], ignore_index=True)\n",
    "pam_combined.drop('MOD_D', axis=1, inplace=True)\n",
    "pam_combined['ID'] = pam_combined['ID'].apply(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "all_combined['ID'] = all_combined['ID'].apply(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7a3892",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pam_combined.head(), pam_combined.shape, pam_combined.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120d43e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_combined['AGE'].unique())\n",
    "print(all_combined['AGE'].isna().sum())\n",
    "print(all_combined.head(), all_combined.shape, all_combined.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a5caed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pam_combined_grouped = pam_combined.groupby('ID')\n",
    "# Initialize the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Iterate over each group\n",
    "for name, group in pam_combined_grouped:\n",
    "    plt.plot(group.index, group['PAXINTEN'], label=name)\n",
    "    print(name)\n",
    "    break\n",
    "# Adding titles and labels\n",
    "plt.title('PAXINTEN by ID')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('PAXINTEN')\n",
    "plt.legend()\n",
    "#plt.legend(title='ID')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7723cf",
   "metadata": {},
   "source": [
    "Create a kombination of IDs based of group blocks contained of SEX -> AGE -> HE_BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df070f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming grouped_df is your DataFrame containing the grouped data\n",
    "#all_combined = all_combined.iloc[1:1000]\n",
    "pam_grouped = pam_combined.groupby('ID')\n",
    "# Create an empty list to store pairs of IDs\n",
    "id_pairs = []\n",
    "group_names = []\n",
    "sex_names = []\n",
    "age_names = []\n",
    "bmi_names = []\n",
    "PHQ_value = np.array([])\n",
    "# Iterate over each group\n",
    "for name, group in all_combined.groupby(['SEX', 'AGE', 'HE_BMI']):\n",
    "    # Get IDs in the group\n",
    "    ids = group['ID'].tolist()\n",
    "    valid_ids = []\n",
    "    for id1 in ids:\n",
    "        try:\n",
    "            data_participant_1 = pam_grouped.get_group(id1)['PAXINTEN'].to_numpy()\n",
    "            valid_ids.append(id1)\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    for id_1 in valid_ids:\n",
    "        for id_2 in valid_ids:\n",
    "            if id_1 == id_2: #or (id_2,id_1) in id_pairs:\n",
    "                pass\n",
    "            else:\n",
    "                id_pairs.append((id_1,id_2))\n",
    "                group_names.append(name[0] + '_' + name[1] + '_' + name[2])\n",
    "                sex_names.append(name[0])\n",
    "                age_names.append(name[1])\n",
    "                bmi_names.append(name[2])\n",
    "\n",
    "                # PHQ9P1 = all_combined.loc[all_combined['ID'] == id_1, 'BP_PHQ_9'].iloc[0]\n",
    "                # PHQ9P2 = all_combined.loc[all_combined['ID'] == id_2, 'BP_PHQ_9'].iloc[0]\n",
    "\n",
    "                PHQSP1 = all_combined.loc[all_combined['ID'] == id_1, 'MH_PHQ_S'].iloc[0]\n",
    "                PHQSP2 = all_combined.loc[all_combined['ID'] == id_2, 'MH_PHQ_S'].iloc[0]\n",
    "                \n",
    "                value = int(PHQSP1 - PHQSP2)\n",
    "                PHQ_value = np.append(PHQ_value, value)\n",
    "    \n",
    "# Convert the list of ID pairs to a DataFrame\n",
    "# Goes from -27 to 27 so with absolute from 0 - 27 possible thresholds = [12, 15, 18, 20, 22, 24]\n",
    "threshold = 15\n",
    "id_pairs_df = pd.DataFrame(id_pairs, columns=['ID_1', 'ID_2'])\n",
    "id_pairs_df['group_id'] = group_names\n",
    "id_pairs_df['SEX'] = sex_names\n",
    "id_pairs_df['AGE'] = age_names\n",
    "id_pairs_df['HE_BMI'] = bmi_names\n",
    "id_pairs_df['ID_COMBINED'] = id_pairs_df['ID_1'] + id_pairs_df['ID_2']\n",
    "id_pairs_df['d_PHQ'] = PHQ_value\n",
    "id_pairs_df['Depression'] = (abs(id_pairs_df['d_PHQ']) >= threshold).astype(int)\n",
    "# Print the DataFrame containing pairs of IDs\n",
    "print(id_pairs_df.head(100), id_pairs_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776f5109",
   "metadata": {},
   "source": [
    "Match ID1 and ID2 with the respectively actigraphy data and create a synthetic dataset with abs(PHQ9P2 - PHQ9P1) as the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e3d310",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_pairs_grouped = id_pairs_df.groupby('d_PHQ')\n",
    "for name, group in id_pairs_grouped:\n",
    "    print(name)\n",
    "    print(group.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6f3bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "pam_synthetic = pd.DataFrame(columns=['ID','ACTIGRAPHY_DATA'], dtype = object)\n",
    "synthetic_array = np.zeros((id_pairs_df.shape[0], 10080)) # 10080 number of samples for a single patient\n",
    "id_combined = []\n",
    "number = 0\n",
    "for index,synthetic_patient in id_pairs_df.iterrows():\n",
    "    \n",
    "    data_participant_1 = pam_grouped.get_group(synthetic_patient['ID_1'])['PAXINTEN'].to_numpy()\n",
    "    data_participant_2 = pam_grouped.get_group(synthetic_patient['ID_2'])['PAXINTEN'].to_numpy()\n",
    "    synthetic_array[number] = (data_participant_1 + data_participant_2) / 2\n",
    "    id_combined.append(synthetic_patient['ID_1'] + synthetic_patient['ID_2'])\n",
    "    logging.info(f\"Participant_1 {synthetic_patient['ID_1']} and Participant_2 {synthetic_patient['ID_2']} added with {synthetic_array[number]}\")\n",
    "    number += 1\n",
    "    \n",
    "pam_synthetic['ID'] = id_combined\n",
    "mask = []\n",
    "for row in range(synthetic_array.shape[0]):\n",
    "    max_value = np.max(synthetic_array[row, :])\n",
    "    if max_value == 0 or max_value == 0.0:\n",
    "        mask.append(row)\n",
    "synthetic_array = np.delete(synthetic_array, mask, axis=0)\n",
    "\n",
    "for row in range(synthetic_array.shape[0]):\n",
    "    pam_synthetic.at[row, 'ACTIGRAPHY_DATA'] = synthetic_array[row]\n",
    "id_pairs_df['ACTIGRAPHY_DATA'] = pam_synthetic['ACTIGRAPHY_DATA']      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd6b9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Define functions to compute statistical features\n",
    "\n",
    "def compute_energy(coeff):\n",
    "    return np.sum(coeff ** 2)\n",
    "\n",
    "def compute_mean(coeff):\n",
    "    return np.mean(coeff)\n",
    "\n",
    "def compute_std(coeff):\n",
    "    return np.std(coeff)\n",
    "\n",
    "def compute_entropy(coeff):\n",
    "    p = np.abs(coeff) / np.sum(np.abs(coeff))\n",
    "    return -np.sum(p * np.log2(p + np.finfo(float).eps))  # eps to avoid log(0)\n",
    "\n",
    "def compute_features(data):\n",
    "    coefficents = np.zeros(len(id_pairs_df))\n",
    "    coeffs = pywt.wavedec(data, 'db1')\n",
    "\n",
    "        #coefficents[index] = coeff\n",
    "        \n",
    "        # for i,participant in enumerate(coefficents):\n",
    "        #     energies = np.square(participant)\n",
    "        #     sorted_indices = np.argsort(energies)[::-1]\n",
    "        #     cumulative_energy = np.cumsum(energies[sorted_indices])\n",
    "        #     total_energy = cumulative_energy[-1]\n",
    "        #     cumulative_energy /= total_energy\n",
    "\n",
    "        #     num_features = np.searchsorted(cumulative_energy, energy_threshold)\n",
    "            \n",
    "        #     important_indices = sorted_indices[:num_features]\n",
    "        #     coefficents[i] = participant[important_indices]\n",
    "\n",
    "    # Extract features from the wavelet coefficients\n",
    "    features = []\n",
    "\n",
    "    for i, coeff in enumerate(coeffs):\n",
    "        features.append(compute_energy(coeff))\n",
    "        features.append(compute_mean(coeff))\n",
    "        features.append(compute_std(coeff))\n",
    "        features.append(compute_entropy(coeff))\n",
    "\n",
    "    # Convert the feature list to a numpy array\n",
    "    features = np.array(features)\n",
    "\n",
    "    # (Optional) Normalize or standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    features = scaler.fit_transform(features.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # print(\"Extracted features:\")\n",
    "    # print(features)\n",
    "\n",
    "    return features\n",
    "\n",
    "feature_list = []\n",
    "for index,participant in id_pairs_df.iterrows():\n",
    "    features = compute_features(participant['ACTIGRAPHY_DATA'])\n",
    "    feature_list.append(features)\n",
    "   \n",
    "id_pairs_df['FEATURES'] = feature_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925d93bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(id_pairs_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dece478",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_pairs_df.drop('ACTIGRAPHY_DATA', axis=1, inplace=True)\n",
    "print(id_pairs_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a030ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_pairs_df.to_csv(f'data/data_threshold_{threshold}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
