{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b48f8a4e-faea-4589-b4b7-fbedfafaf19e",
   "metadata": {},
   "source": [
    "# Task 2: Random Data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527419fe-8e73-4bd4-bde5-28cdcc92a861",
   "metadata": {},
   "source": [
    "## Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae778c4-8eaa-4b28-91f9-58004a71f914",
   "metadata": {},
   "source": [
    "> I ran the following code for a binary classification task w/ an SVM in both R (first sample) and Python (second example).\n",
    ">\n",
    "> Given randomly generated data (X) and response (Y), this code performs leave group out cross validation 1000 times. Each entry of Y is therefore the mean of the prediction across CV iterations.\n",
    "> \n",
    "> Computing area under the curve should give ~0.5, since X and Y are completely random. However, this is not what we see. Area under the curve is frequently significantly higher than 0.5. The number of rows of X is very small, which can obviously cause problems.\n",
    ">\n",
    "> Any idea what could be happening here? I know that I can either increase the number of rows of X or decrease the number of columns to mediate the problem, but I am looking for other issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fa08c3",
   "metadata": {},
   "source": [
    "```R\n",
    "Y=as.factor(rep(c(1,2), times=14))\n",
    "X=matrix(runif(length(Y)*100), nrow=length(Y))\n",
    "\n",
    "library(e1071)\n",
    "library(pROC)\n",
    "\n",
    "colnames(X)=1:ncol(X)\n",
    "iter=1000\n",
    "ansMat=matrix(NA,length(Y),iter)\n",
    "for(i in seq(iter)){    \n",
    "    #get train\n",
    "\n",
    "    train=sample(seq(length(Y)),0.5*length(Y))\n",
    "    if(min(table(Y[train]))==0)\n",
    "    next\n",
    "\n",
    "    #test from train\n",
    "    test=seq(length(Y))[-train]\n",
    "\n",
    "    #train model\n",
    "    XX=X[train,]\n",
    "    YY=Y[train]\n",
    "    mod=svm(XX,YY,probability=FALSE)\n",
    "    XXX=X[test,]\n",
    "    predVec=predict(mod,XXX)\n",
    "    RFans=attr(predVec,'decision.values')\n",
    "    ansMat[test,i]=as.numeric(predVec)\n",
    "}\n",
    "\n",
    "ans=rowMeans(ansMat,na.rm=TRUE)\n",
    "\n",
    "r=roc(Y,ans)$auc\n",
    "print(r)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14e4617-608b-4749-9ec5-edf15814f5bf",
   "metadata": {},
   "source": [
    "Similarly, when I implement the same thing in Python I get similar results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cf44d8d-ca36-4d6b-bafd-78cade069751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7704081632653061\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "Y = np.array([1, 2]*14)\n",
    "X = np.random.uniform(size=[len(Y), 100])\n",
    "n_iter = 1000\n",
    "ansMat = np.full((len(Y), n_iter), np.nan)\n",
    "for i in range(n_iter):\n",
    "    # Get train/test index\n",
    "    train = np.random.choice(range(len(Y)), size=int(0.5*len(Y)), replace=False, p=None)\n",
    "    if len(np.unique(Y)) == 1:\n",
    "        continue\n",
    "    test = np.array([i for i in range(len(Y)) if i not in train])\n",
    "    # train model\n",
    "    mod = SVC(probability=False)\n",
    "    mod.fit(X=X[train, :], y=Y[train])\n",
    "    # predict and collect answer\n",
    "    ansMat[test, i] = mod.predict(X[test, :])\n",
    "ans = np.nanmean(ansMat, axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(Y, ans, pos_label=1)\n",
    "print(auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504cde2c-c5fd-4bc8-8aba-efb044d31198",
   "metadata": {},
   "source": [
    "## Your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6ca1fc",
   "metadata": {},
   "source": [
    "The problem in the code is that the Y variable was created with the values 1 and 2. As a result, the variable was not treated as a binary variable, but as a numeric variable. By rewriting the variable with the values 0 and 1, it is ensured that the variable is treated as a binary variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "345378d9-436b-42d6-8444-4d0edc4b1ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.030612244897959186\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "Y = np.array([0,1]*14)\n",
    "X = np.random.uniform(size=[len(Y), 100])\n",
    "n_iter = 1000\n",
    "ansMat = np.full((len(Y), n_iter), np.nan)\n",
    "for i in range(n_iter):\n",
    "    # Get train/test index\n",
    "    train = np.random.choice(range(len(Y)), size=int(0.5*len(Y)), replace=False, p=None)\n",
    "    if len(np.unique(Y)) == 1:\n",
    "        continue\n",
    "    test = np.array([i for i in range(len(Y)) if i not in train])\n",
    "    # train model\n",
    "    mod = SVC(probability=False)\n",
    "    mod.fit(X=X[train, :], y=Y[train])\n",
    "    # predict and collect answer\n",
    "    ansMat[test, i] = mod.predict(X[test, :])\n",
    "ans = np.nanmean(ansMat, axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(Y, ans, pos_label=1)\n",
    "print(auc(fpr, tpr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
